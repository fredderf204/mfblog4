[{"content":" I am a Microsoft employee, but the views expressed here are mine and not those of my employer.\nThis is part 2 of an ongoing series on simple Gen AI Product Recommendation System that you can POC quickly. If you missed the first post in the series, you can find it here.\nIn this post, we will expand our simple Gen AI Product Recommendation System by increasing our data set and using cloud services to scale our solution. Lastly we will be using some more advanced prompt engineering techniques to improve the quality of our recommendations.\nBut\u0026hellip;\u0026hellip; why would you want to do this??? once you have completed this walk through, you will have a vector store setup in Azure and the ability to experiment with different searching techniques. As well as Azure Open AI setup to experiment with different prompt engineering techniques to get the best results for you project.\nTLDR If you just want to see the code, you can find it here\nIf you want to skip to the good stuff at the end of this blog post, you can find it searching techniques here and prompt engineering techniques here.\nAll you need is a CSV file or JSON file with customer and product performance data to use this sample. A sample CSV file has been included in the GitHub repo if you just want to run through the process.\nPre-requisites To follow along with this post, you will need the following already running in Azure:\nAzure Open AI. I use the text-embedding-3-large model to vectorise the CSV or JSON file (more details on this later) and the question. I also use the GPT-4o model to recommend the next best product to the customer. You can sign up for Azure Open AI here\nAzure AI Search. I use Azure AI Search for various things in the sample, but mainly to index the JSON file, store the embeddings and search for similar customer profiles (more details on this later). You can sign up for Azure AI Search here.\nAzure Blob Storage. I use Azure Blob Storage to store the CSV or JSON file.\nIntroduction In the first post, we built a simple Gen AI Product Recommendation System that used a small dataset to provide product recommendations to customers. We used a generative AI model to generate recommendations based on the customer\u0026rsquo;s product performance. In this post, we will expand our dataset and use cloud services to scale our solution. We will also use some more advanced prompt engineering techniques to improve the quality of our recommendations.\nThe has 2 files that you need to follow in order;\n02-prepcsv.py 02-csv.ipynb Also I create a larger dataset using a combination of python and Microsoft excel. The dataset is called test-recsys-data-5000.csv and can be found in the data folder. It has 5000 rows of sample data.\n02-prepcsv.py This scripts does a couple of things to prepare the CSV file for indexing in Azure AI Search.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import os import pandas as pd # Read the CSV file with specified data types csv_input=pd.read_csv( os.path.join(os.getcwd(),\u0026#39;./data/test-recsys-data-5000.csv\u0026#39;), dtype={ \u0026#39;CompanyName\u0026#39;:str, \u0026#39;State\u0026#39;:str, \u0026#39;Industry\u0026#39;:str, \u0026#39;Segment\u0026#39;:str, \u0026#39;Product 1 Name\u0026#39;:str,\u0026#39;Product 1 Performance\u0026#39;:float, \u0026#39;Product 2 Name\u0026#39;:str,\u0026#39;Product 2 Performance\u0026#39;:float, \u0026#39;Product 3 Name\u0026#39;:str,\u0026#39;Product 3 Performance\u0026#39;:float, \u0026#39;Product 4 Name\u0026#39;:str,\u0026#39;Product 4 Performance\u0026#39;:float, \u0026#39;Product 5 Name\u0026#39;:str,\u0026#39;Product 5 Performance\u0026#39;:float, \u0026#39;Product 6 Name\u0026#39;:str,\u0026#39;Product 6 Performance\u0026#39;:float, \u0026#39;Product 7 Name\u0026#39;:str,\u0026#39;Product 7 Performance\u0026#39;:float, \u0026#39;Product 8 Name\u0026#39;:str,\u0026#39;Product 8 Performance\u0026#39;:float } ) Lines 1 - 21 read the csv files, create a pandas dataframe and casts the columns to the correct data types.\n1 csv_input[\u0026#39;json\u0026#39;] = csv_input.apply(lambda x: x.to_json(), axis=1) Line 24 creates a new column called json and converts the row to a JSON string. The reason I do this is similar to the first post, when I have found the similar customer profiles to my target profile, I can use the JSON string as input to the generative AI model to recommend the next best product.\n1 2 performance_columns = [col for col in csv_input.columns if \u0026#39;Performance\u0026#39; in col] csv_input[\u0026#39;performance\u0026#39;] = csv_input[performance_columns].mean(axis=1, skipna=True) Line 27 and 28 create a new column called performance and calculates the mean of the performance columns. Just like in the first example, I have arbitrary numbers in the performance columns. You might have actual performance data in your dataset and a way of calculating the product portfolio performance of the customer. I simply take the mean of the performance columns to get a single number to represent the customer\u0026rsquo;s product portfolio performance.\n1 2 cols=[\u0026#39;State\u0026#39;,\u0026#39;Industry\u0026#39;,\u0026#39;Segment\u0026#39;] csv_input[\u0026#39;prof\u0026#39;] = csv_input[cols].apply(lambda row: \u0026#39; \u0026#39;.join(row.values.astype(str)), axis=1) Again as in the first example, I am using the State, Industry and Segment columns to create a profile of the customer. I concatenate the values of these columns to create a single string that represents the customer profile. You might have another way of creating a customer profile or have more data points to create the customer profile, but this is a simple way to do it.\nThe customer profile is important as is what\u0026rsquo;s used to find similar customer profiles in the dataset. The more accurate the customer profile, the more chance of finding similar customer profiles.\n1 csv_input.to_json(\u0026#39;02/data/output1.json\u0026#39;, orient=\u0026#39;records\u0026#39;) Finally I saved the dataframe to a JSON file. This is the file that will be uploaded to Azure Blob Storage and indexed in Azure AI Search. The reason I chose JSON is that it\u0026rsquo;s easier to work with in Azure AI Search. So if you have started with JSON, you will just need to create a dataframe from that JSOn and start at line 24.\n02-csv.ipynb I have used an existing sample created my Microsoft and tweaked it for our needs. You can find the original sample here. The code flows as follows;\nSetup Python environment Upload the JSON file to Azure Blob Storage Create a blob data source connector on Azure AI Search Create a search index on Azure AI Search Create an skillset on Azure AI Search Create an indexer on Azure AI Search Query the index Make recommendations using Azure Open AI I have added some additional code to the sample to make it easier to follow. The code is well commented and should be easy to follow.\nSetup Python environment If you are not new to Python, this setup should be familiar to you. If you are new to Python, the notebook as some good detail on how to setup your Python environment using VS Code.\nI can be a little tricky to figure out which environment variables to use and add to your .env file. So I have listed the ones that i used; AZURE_SEARCH_SERVICE_ENDPOINT, AZURE_SEARCH_ADMIN_KEY, AZURE_SEARCH_INDEX, BLOB_CONNECTION_STRING, BLOB_CONTAINER_NAME, AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_KEY, AZURE_OPENAI_EMBEDDING_DEPLOYMENT, AZURE_OPENAI_EMBEDDING_MODEL_NAME, AZURE_OPENAI_EMBEDDING_DIMENSIONS, AZURE_OPENAI_CHATGPT_DEPLOYMENT and AZURE_OPENAI_API_VERSION.\nUpload the JSON file to Azure Blob Storage This part of the notebook is pretty straight forward. If you have run through the 02-prepcsv.py script, you should have a JSON file called output1.json in the data folder. This code will take that file and upload it to Azure Blob Storage using the connection string and blob container name you have in your environment variables.\nCreate a blob data source connector on Azure AI Search Again, this part of the notebook is also straight forward. You will need to create a blob data source connector on Azure AI Search. The code will create the connector so it can be used in subsequent steps.\nCreate a search index on Azure AI Search OK, now for some more interesting stuff with Azure AI Search.\n1 2 3 4 5 6 7 8 9 index_client = SearchIndexClient(endpoint=endpoint, credential=credential) fields = [ SearchField(name=\u0026#34;AzureSearch_DocumentKey\u0026#34;, key=True, type=SearchFieldDataType.String), SearchField(name=\u0026#34;CompanyName\u0026#34;, type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False), SearchField(name=\u0026#34;performance\u0026#34;, type=SearchFieldDataType.Double, sortable=True, filterable=True, facetable=False), SearchField(name=\u0026#34;prof\u0026#34;, type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False), SearchField(name=\u0026#34;json\u0026#34;, type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False), SearchField(name=\u0026#34;prof_vector\u0026#34;, type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=azure_openai_model_dimensions, vector_search_profile_name=\u0026#34;myHnswProfile\u0026#34;), ] This code snippet creates a search index client and is the configuration to create the search index. The index has 5 fields, AzureSearch_DocumentKey, CompanyName, performance, prof and json. The AzureSearch_DocumentKey is the unique key for the index and is automatically generated by the indexer. The CompanyName is the name of the company. The performance is the performance of the customer\u0026rsquo;s product portfolio. The prof is the customer profile. The json is the JSON string of the customer\u0026rsquo;s product performance. The prof_vector is the vectorised version of the customer profile.\nNotice that theses fields are the same as the columns in the JSON file. This is important as the indexer will use these fields to index the JSON file.\nLastly, the prof_vector is something that doesn\u0026rsquo;t exist yet. This will be a vectorised version of the customer profile and will be created by our indexer later in this code. So for now, just know that it will be created and will hold the vectorised version of the customer profile.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # Configure the vector search configuration vector_search = VectorSearch( algorithms=[ HnswAlgorithmConfiguration(name=\u0026#34;myHnsw\u0026#34;), ], profiles=[ VectorSearchProfile( name=\u0026#34;myHnswProfile\u0026#34;, algorithm_configuration_name=\u0026#34;myHnsw\u0026#34;, vectorizer=\u0026#34;myOpenAI\u0026#34;, ) ], vectorizers=[ AzureOpenAIVectorizer( name=\u0026#34;myOpenAI\u0026#34;, kind=\u0026#34;azureOpenAI\u0026#34;, azure_open_ai_parameters=AzureOpenAIParameters( resource_uri=azure_openai_endpoint, deployment_id=azure_openai_embedding_deployment, model_name=azure_openai_model_name, api_key=azure_openai_key, ), ), ], ) This next part of the code will configure the vector search configuration. I used the default HNSW algorithm and the Azure Open AI vectoriser. If you would like to learn more about the HNSW algorithm, you can find more information here.\n1 2 3 4 5 6 7 semantic_config = SemanticConfiguration( name=\u0026#34;my-semantic-config\u0026#34;, prioritized_fields=SemanticPrioritizedFields( title_field=SemanticField(field_name=\u0026#34;CompanyName\u0026#34;), content_fields=[SemanticField(field_name=\u0026#34;prof\u0026#34;)] ), ) Now this section of the code is where you configure the semantic configuration. The semantic configuration is used to configure semantic ranking. Semantic ranking iterates over an initial result set, applying an L2 ranking methodology that promotes the most semantically relevant results to the top of the stack.. I have added this section if some we can play around with semantic ranking later in this code.\nCreate an skillset on Azure AI Search This part of the code creates a skillset on Azure AI Search. The skillset is used to create the vectorised version of the customer profile. The skillset uses the Azure Open AI vectoriser to create the vectorised version of the customer profile.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 csv_comb_embedding_skill = AzureOpenAIEmbeddingSkill( description=\u0026#34;Skill to generate comb embeddings via Azure OpenAI\u0026#34;, context=\u0026#34;/document\u0026#34;, resource_uri=azure_openai_endpoint, deployment_id=azure_openai_embedding_deployment, model_name=azure_openai_model_name, dimensions=azure_openai_model_dimensions, api_key=azure_openai_key, inputs=[ InputFieldMappingEntry(name=\u0026#34;text\u0026#34;, source=\u0026#34;/document/prof\u0026#34;), ], outputs=[ OutputFieldMappingEntry(name=\u0026#34;embedding\u0026#34;, target_name=\u0026#34;prof_vector\u0026#34;), ], ) skills = [csv_comb_embedding_skill] This code snippet above is the configuration for the skillset. The main parts of the configuration to look out for are the context - which is the path to the document in the JSON file. I just left this as the default /document. The inputs - which is the field in the JSON file that will be vectorised. name should be text and source should be /document/prof, as it\u0026rsquo;s the prof field we want vectorised. And lastly, the outputs - which is the field in the search index that will hold the vectorised version of the customer profile. name should be embedding and source should be prof_vector.\nCreate an indexer on Azure AI Search The indexer is the part of Azure AI Search that brings together the data source, the search index and the skillset. The indexer will use the data source to index the JSON file, use the skillset to create the vectorised version of the customer profile and use the search index to store the data.\n1 2 3 4 5 6 indexer_name = f\u0026#34;{index_name}-indexer\u0026#34; indexer_parameters = IndexingParameters( configuration=IndexingParametersConfiguration( parsing_mode=\u0026#39;jsonArray\u0026#39;, query_timeout=None, first_line_contains_headers=True)) This code snippet above is the configuration for the indexing parameters. The main parts of the configuration to look out for are the parsing_mode - which is the mode the indexer will use to parse the JSON file. I have used jsonArray as the JSON file is an array of JSON objects and this parsing mode will take each JSON object and create a document in the search index. I.e. one JSON file to many documents in the search index.\nThere are other types of parsing modes out there for Azure AI Search to parse standalone files or embedded objects of various content types in data sources like Azure Blob Storage, Azure Data Lake Storage Gen2, and SharePoint. You can learn about them here.\n1 2 3 4 5 6 7 8 9 10 11 12 indexer = SearchIndexer( name=indexer_name, description=\u0026#34;Indexer to index documents and generate embeddings\u0026#34;, skillset_name=skillset_name, target_index_name=index_name, data_source_name=data_source.name, parameters=indexer_parameters, field_mappings=[FieldMapping(source_field_name=\u0026#34;AzureSearch_DocumentKey\u0026#34;, target_field_name=\u0026#34;AzureSearch_DocumentKey\u0026#34;, mapping_function=FieldMappingFunction(name=\u0026#34;base64Encode\u0026#34;))], output_field_mappings=[ FieldMapping(source_field_name=\u0026#34;/document/prof_vector\u0026#34;, target_field_name=\u0026#34;prof_vector\u0026#34;), ] ) Now for the search indexer parameters configuration, which is above. This is the part that ties together the data source, the search index and the skillset. The main parts of the configuration to look out for are the skillset_name - which is the name of the skillset that will be used to create the vectorised version of the customer profile. The target_index_name - which is the name of the search index that will store the data. The data_source_name - which is the name of the data source that will be used to index the JSON file. The field_mappings - which is the field mapping that will be used to map the system created AzureSearch_DocumentKey field to the AzureSearch_DocumentKey field in the search index. The output_field_mappings - which is the field mapping that will be used to map the prof_vector field in the JSON file to the prof_vector field in the search index.\nQuery the index Now we can have some fun!\nThere are different types of queries you can run on the search index which fall in the retrieval bucket, which you can read about here. The good news is that we are setup to try out full text search, vector search and hybrid search. Also we are setup to try out semantic ranking.\nThere is a good blog post here which goes into more details about all of this.\nBut the purpose of the next part of the notebook is to return the top 20 similar customer profiles to the target customer profile. I have picked 20 for no particular reason, but feel free to try out some different numbers and see how that affects your results.\n1 2 3 4 target_company = \u0026#39;[{\u0026#34;CompanyName\u0026#34;:\u0026#34;Madeup Inc\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:\u0026#34;Widget W\u0026#34;,\u0026#34;Product 1 Performance\u0026#34;:85,\u0026#34;Product 2 Name\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;Product 2 Performance\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;Product 3 Name\u0026#34;:\u0026#34;Widget Y\u0026#34;,\u0026#34;Product 3 Performance\u0026#34;:74}]\u0026#39; company_data = json.loads(target_company)[0] query = f\u0026#34;{company_data[\u0026#39;State\u0026#39;]} {company_data[\u0026#39;Industry\u0026#39;]} {company_data[\u0026#39;Segment\u0026#39;]}\u0026#34; print(f\u0026#34;Query: {query}\u0026#34;) For this code snippet, I have made up a target customer profile called target_company. This is a JSON string that represents the target customer full information, including individual product performance. I have used the State, Industry and Segment columns to create the target customer profile, which I have saved as query.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 search_client = SearchClient(endpoint, index_name, credential=credential) vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=50, fields=\u0026#34;prof_vector\u0026#34;) results = search_client.search( search_text=query, #vector_queries= [vector_query], select=[\u0026#34;CompanyName\u0026#34;, \u0026#34;prof\u0026#34;, \u0026#34;performance\u0026#34;, \u0026#34;json\u0026#34;], filter=\u0026#34;performance ge 60\u0026#34;, top=20, include_total_count=True ) print (\u0026#39;Total Documents Matching Query:\u0026#39;, results.get_count()) print(\u0026#34;-\u0026#34; * 50) comp_profiles = [] for result in results: print(f\u0026#34;Score: {result[\u0026#39;@search.score\u0026#39;]}\u0026#34;) print(f\u0026#34;CompanyName: {result[\u0026#39;CompanyName\u0026#39;]}\u0026#34;) print(f\u0026#34;profile: {result[\u0026#39;prof\u0026#39;]}\u0026#34;) print(f\u0026#34;performance: {result[\u0026#39;performance\u0026#39;]}\u0026#34;) print(f\u0026#34;json: {result[\u0026#39;json\u0026#39;]}\u0026#34;) comp_profiles.append(result[\u0026#39;json\u0026#39;]) print(\u0026#34;-\u0026#34; * 50) Now if you look at the code above, I have created a search client and I am only using the search_text parameter, which means I am doing a full text search. I have also commented out the vector_queries parameter, which means I am not doing a vector search (but we can add it in right after this).\nNow I have added the line filter=\u0026ldquo;performance ge 60\u0026rdquo; to filter out any search results that do not have high product performance. This is because later in the code I want to make recommendations based on the high performing products of the customer. This is by no means a perfect solution, but it\u0026rsquo;s a simple way to filter out low performing products.\nWhich produces the below results, which I have truncated for brevity;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Query: NSW Finance Banking Total Documents Matching Query: 404 -------------------------------------------------- Score: 13.586723 CompanyName: Sky Robotics profile: NSW Finance Banking performance: 61.25 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Sky Robotics\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:\u0026#34;Widget W\u0026#34;,\u0026#34;Product 1 Performance\u0026#34;:75.0,\u0026#34;Product 2 Name\u0026#34;:\u0026#34;Widget X\u0026#34;,\u0026#34;Product 2 Performance\u0026#34;:87.0,\u0026#34;Product 3 Name\u0026#34;:null,\u0026#34;Product 3 Performance\u0026#34;:null,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:21.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:null,\u0026#34;Product 7 Performance\u0026#34;:null,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:62.0} -------------------------------------------------- Score: 13.586723 CompanyName: Consulting Apex profile: NSW Finance Banking performance: 61.0 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Consulting Apex\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:null,\u0026#34;Product 1 Performance\u0026#34;:null,\u0026#34;Product 2 Name\u0026#34;:null,\u0026#34;Product 2 Performance\u0026#34;:null,\u0026#34;Product 3 Name\u0026#34;:\u0026#34;Widget Y\u0026#34;,\u0026#34;Product 3 Performance\u0026#34;:58.0,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:81.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:56.0,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:49.0} -------------------------------------------------- Score: 13.266863 CompanyName: Orion Consulting profile: NSW Finance Banking performance: 65.0 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Orion Consulting\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:null,\u0026#34;Product 1 Performance\u0026#34;:null,\u0026#34;Product 2 Name\u0026#34;:null,\u0026#34;Product 2 Performance\u0026#34;:null,\u0026#34;Product 3 Name\u0026#34;:null,\u0026#34;Product 3 Performance\u0026#34;:null,\u0026#34;Product 4 Name\u0026#34;:null,\u0026#34;Product 4 Performance\u0026#34;:null,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:\u0026#34;Gizmo B\u0026#34;,\u0026#34;Product 6 Performance\u0026#34;:64.0,\u0026#34;Product 7 Name\u0026#34;:null,\u0026#34;Product 7 Performance\u0026#34;:null,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:66.0} -------------------------------------------------- Score: 12.660498 CompanyName: Dynamics Arcadia profile: NSW Finance Banking performance: 67.0 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Dynamics Arcadia\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:\u0026#34;Widget W\u0026#34;,\u0026#34;Product 1 Performance\u0026#34;:49.0,\u0026#34;Product 2 Name\u0026#34;:null,\u0026#34;Product 2 Performance\u0026#34;:null,\u0026#34;Product 3 Name\u0026#34;:null,\u0026#34;Product 3 Performance\u0026#34;:null,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:90.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:62.0,\u0026#34;Product 8 Name\u0026#34;:null,\u0026#34;Product 8 Performance\u0026#34;:null} -------------------------------------------------- Score: 12.314001 CompanyName: Nexus Hyper profile: NSW Finance Banking performance: 68.8333333333 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Nexus Hyper\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:\u0026#34;Widget W\u0026#34;,\u0026#34;Product 1 Performance\u0026#34;:49.0,\u0026#34;Product 2 Name\u0026#34;:\u0026#34;Widget X\u0026#34;,\u0026#34;Product 2 Performance\u0026#34;:85.0,\u0026#34;Product 3 Name\u0026#34;:\u0026#34;Widget Y\u0026#34;,\u0026#34;Product 3 Performance\u0026#34;:92.0,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:15.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:\u0026#34;Gizmo B\u0026#34;,\u0026#34;Product 6 Performance\u0026#34;:93.0,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:79.0,\u0026#34;Product 8 Name\u0026#34;:null,\u0026#34;Product 8 Performance\u0026#34;:null} And as you can see, all of the top 5 results also have a profile of NSW Finance Banking and have a performance of over 60. And if we look at the bottom 3 matches (matched 18-20), they have veered off the profile a little bit, but you can see are still related to the target profile. This is a good sign that the search index is working as expected.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Score: 9.345702 CompanyName: Octogon Craft profile: SA Finance Banking performance: 79.4 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Octogon Craft\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;SA\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:null,\u0026#34;Product 1 Performance\u0026#34;:null,\u0026#34;Product 2 Name\u0026#34;:null,\u0026#34;Product 2 Performance\u0026#34;:null,\u0026#34;Product 3 Name\u0026#34;:null,\u0026#34;Product 3 Performance\u0026#34;:null,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:87.0,\u0026#34;Product 5 Name\u0026#34;:\u0026#34;Gizmo A\u0026#34;,\u0026#34;Product 5 Performance\u0026#34;:68.0,\u0026#34;Product 6 Name\u0026#34;:\u0026#34;Gizmo B\u0026#34;,\u0026#34;Product 6 Performance\u0026#34;:94.0,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:85.0,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:63.0} -------------------------------------------------- Score: 9.345702 CompanyName: Sea Communications profile: VIC Finance Banking performance: 69.0 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Sea Communications\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;VIC\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:null,\u0026#34;Product 1 Performance\u0026#34;:null,\u0026#34;Product 2 Name\u0026#34;:\u0026#34;Widget X\u0026#34;,\u0026#34;Product 2 Performance\u0026#34;:93.0,\u0026#34;Product 3 Name\u0026#34;:\u0026#34;Widget Y\u0026#34;,\u0026#34;Product 3 Performance\u0026#34;:78.0,\u0026#34;Product 4 Name\u0026#34;:null,\u0026#34;Product 4 Performance\u0026#34;:null,\u0026#34;Product 5 Name\u0026#34;:\u0026#34;Gizmo A\u0026#34;,\u0026#34;Product 5 Performance\u0026#34;:92.0,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:13.0,\u0026#34;Product 8 Name\u0026#34;:null,\u0026#34;Product 8 Performance\u0026#34;:null} -------------------------------------------------- Score: 9.345702 CompanyName: Square Dynamics profile: VIC Finance Banking performance: 63.25 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Square Dynamics\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;VIC\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:null,\u0026#34;Product 1 Performance\u0026#34;:null,\u0026#34;Product 2 Name\u0026#34;:\u0026#34;Widget X\u0026#34;,\u0026#34;Product 2 Performance\u0026#34;:33.0,\u0026#34;Product 3 Name\u0026#34;:\u0026#34;Widget Y\u0026#34;,\u0026#34;Product 3 Performance\u0026#34;:83.0,\u0026#34;Product 4 Name\u0026#34;:null,\u0026#34;Product 4 Performance\u0026#34;:null,\u0026#34;Product 5 Name\u0026#34;:\u0026#34;Gizmo A\u0026#34;,\u0026#34;Product 5 Performance\u0026#34;:43.0,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:null,\u0026#34;Product 7 Performance\u0026#34;:null,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:94.0} -------------------------------------------------- Now lets look at the vector search results \u0026#x1f604; but remember to uncomment the vector_queries parameter in the search client and comment out the search_text parameter. It should look like this;\n1 2 3 4 5 6 7 8 results = search_client.search( #search_text=query, vector_queries= [vector_query], select=[\u0026#34;CompanyName\u0026#34;, \u0026#34;prof\u0026#34;, \u0026#34;performance\u0026#34;, \u0026#34;json\u0026#34;], filter=\u0026#34;performance ge 60\u0026#34;, top=20, include_total_count=True ) And the results should look like this;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Query: NSW Finance Banking Total Documents Matching Query: 50 -------------------------------------------------- Score: 0.9999994 CompanyName: Sky Robotics profile: NSW Finance Banking performance: 61.25 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Sky Robotics\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:\u0026#34;Widget W\u0026#34;,\u0026#34;Product 1 Performance\u0026#34;:75.0,\u0026#34;Product 2 Name\u0026#34;:\u0026#34;Widget X\u0026#34;,\u0026#34;Product 2 Performance\u0026#34;:87.0,\u0026#34;Product 3 Name\u0026#34;:null,\u0026#34;Product 3 Performance\u0026#34;:null,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:21.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:null,\u0026#34;Product 7 Performance\u0026#34;:null,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:62.0} -------------------------------------------------- Score: 0.9999994 CompanyName: Consulting Apex profile: NSW Finance Banking performance: 61.0 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Consulting Apex\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:null,\u0026#34;Product 1 Performance\u0026#34;:null,\u0026#34;Product 2 Name\u0026#34;:null,\u0026#34;Product 2 Performance\u0026#34;:null,\u0026#34;Product 3 Name\u0026#34;:\u0026#34;Widget Y\u0026#34;,\u0026#34;Product 3 Performance\u0026#34;:58.0,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:81.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:56.0,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:49.0} -------------------------------------------------- Score: 0.9999994 CompanyName: Dynamics Arcadia profile: NSW Finance Banking performance: 67.0 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Dynamics Arcadia\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:\u0026#34;Widget W\u0026#34;,\u0026#34;Product 1 Performance\u0026#34;:49.0,\u0026#34;Product 2 Name\u0026#34;:null,\u0026#34;Product 2 Performance\u0026#34;:null,\u0026#34;Product 3 Name\u0026#34;:null,\u0026#34;Product 3 Performance\u0026#34;:null,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:90.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:62.0,\u0026#34;Product 8 Name\u0026#34;:null,\u0026#34;Product 8 Performance\u0026#34;:null} -------------------------------------------------- Score: 0.9999994 CompanyName: Nexus Hyper profile: NSW Finance Banking performance: 68.8333333333 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Nexus Hyper\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:\u0026#34;Widget W\u0026#34;,\u0026#34;Product 1 Performance\u0026#34;:49.0,\u0026#34;Product 2 Name\u0026#34;:\u0026#34;Widget X\u0026#34;,\u0026#34;Product 2 Performance\u0026#34;:85.0,\u0026#34;Product 3 Name\u0026#34;:\u0026#34;Widget Y\u0026#34;,\u0026#34;Product 3 Performance\u0026#34;:92.0,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:15.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:\u0026#34;Gizmo B\u0026#34;,\u0026#34;Product 6 Performance\u0026#34;:93.0,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:79.0,\u0026#34;Product 8 Name\u0026#34;:null,\u0026#34;Product 8 Performance\u0026#34;:null} -------------------------------------------------- Score: 0.9999994 CompanyName: Orion Consulting profile: NSW Finance Banking performance: 65.0 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Orion Consulting\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:null,\u0026#34;Product 1 Performance\u0026#34;:null,\u0026#34;Product 2 Name\u0026#34;:null,\u0026#34;Product 2 Performance\u0026#34;:null,\u0026#34;Product 3 Name\u0026#34;:null,\u0026#34;Product 3 Performance\u0026#34;:null,\u0026#34;Product 4 Name\u0026#34;:null,\u0026#34;Product 4 Performance\u0026#34;:null,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:\u0026#34;Gizmo B\u0026#34;,\u0026#34;Product 6 Performance\u0026#34;:64.0,\u0026#34;Product 7 Name\u0026#34;:null,\u0026#34;Product 7 Performance\u0026#34;:null,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:66.0} And as you can see, the results are the same as the full text search results, just in a slight different order, as all of the vectors match with a score of 0.9999994. This is a good sign that the vector search is working as expected.\nNow lets look at the bottom 3 matches (matched 18-20) and see how they compare to the full text search results.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Score: 0.8401246 CompanyName: Innovations Strategies profile: NSW Finance Software performance: 60.1666666667 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Innovations Strategies\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Software\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:null,\u0026#34;Product 1 Performance\u0026#34;:null,\u0026#34;Product 2 Name\u0026#34;:\u0026#34;Widget X\u0026#34;,\u0026#34;Product 2 Performance\u0026#34;:85.0,\u0026#34;Product 3 Name\u0026#34;:\u0026#34;Widget Y\u0026#34;,\u0026#34;Product 3 Performance\u0026#34;:31.0,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:27.0,\u0026#34;Product 5 Name\u0026#34;:\u0026#34;Gizmo A\u0026#34;,\u0026#34;Product 5 Performance\u0026#34;:76.0,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:70.0,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:72.0} -------------------------------------------------- Score: 0.8401246 CompanyName: Moon Force profile: NSW Finance Software performance: 61.0 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Moon Force\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Software\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:null,\u0026#34;Product 1 Performance\u0026#34;:null,\u0026#34;Product 2 Name\u0026#34;:null,\u0026#34;Product 2 Performance\u0026#34;:null,\u0026#34;Product 3 Name\u0026#34;:null,\u0026#34;Product 3 Performance\u0026#34;:null,\u0026#34;Product 4 Name\u0026#34;:null,\u0026#34;Product 4 Performance\u0026#34;:null,\u0026#34;Product 5 Name\u0026#34;:\u0026#34;Gizmo A\u0026#34;,\u0026#34;Product 5 Performance\u0026#34;:75.0,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:33.0,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:75.0} -------------------------------------------------- Score: 0.8401246 CompanyName: Aether Consulting profile: NSW Finance Software performance: 61.5 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Aether Consulting\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Software\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:\u0026#34;Widget W\u0026#34;,\u0026#34;Product 1 Performance\u0026#34;:92.0,\u0026#34;Product 2 Name\u0026#34;:null,\u0026#34;Product 2 Performance\u0026#34;:null,\u0026#34;Product 3 Name\u0026#34;:null,\u0026#34;Product 3 Performance\u0026#34;:null,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:40.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:70.0,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:44.0} -------------------------------------------------- And as you can see, the bottom 3 matches are still related to the target profile, but are different to the full text search results.\nLastly, lets look at hybrid search results. To do this, you will need to uncomment the vector_queries parameter in the search client and the search_text parameter. And the results should look like this;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Query: NSW Finance Banking Total Documents Matching Query: 404 -------------------------------------------------- Score: 0.03333333507180214 CompanyName: Sky Robotics profile: NSW Finance Banking performance: 61.25 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Sky Robotics\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:\u0026#34;Widget W\u0026#34;,\u0026#34;Product 1 Performance\u0026#34;:75.0,\u0026#34;Product 2 Name\u0026#34;:\u0026#34;Widget X\u0026#34;,\u0026#34;Product 2 Performance\u0026#34;:87.0,\u0026#34;Product 3 Name\u0026#34;:null,\u0026#34;Product 3 Performance\u0026#34;:null,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:21.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:null,\u0026#34;Product 7 Performance\u0026#34;:null,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:62.0} -------------------------------------------------- Score: 0.032786883413791656 CompanyName: Consulting Apex profile: NSW Finance Banking performance: 61.0 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Consulting Apex\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:null,\u0026#34;Product 1 Performance\u0026#34;:null,\u0026#34;Product 2 Name\u0026#34;:null,\u0026#34;Product 2 Performance\u0026#34;:null,\u0026#34;Product 3 Name\u0026#34;:\u0026#34;Widget Y\u0026#34;,\u0026#34;Product 3 Performance\u0026#34;:58.0,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:81.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:56.0,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:49.0} -------------------------------------------------- Score: 0.0320020467042923 CompanyName: Dynamics Arcadia profile: NSW Finance Banking performance: 67.0 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Dynamics Arcadia\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:\u0026#34;Widget W\u0026#34;,\u0026#34;Product 1 Performance\u0026#34;:49.0,\u0026#34;Product 2 Name\u0026#34;:null,\u0026#34;Product 2 Performance\u0026#34;:null,\u0026#34;Product 3 Name\u0026#34;:null,\u0026#34;Product 3 Performance\u0026#34;:null,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:90.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:null,\u0026#34;Product 6 Performance\u0026#34;:null,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:62.0,\u0026#34;Product 8 Name\u0026#34;:null,\u0026#34;Product 8 Performance\u0026#34;:null} -------------------------------------------------- Score: 0.0317540317773819 CompanyName: Orion Consulting profile: NSW Finance Banking performance: 65.0 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Orion Consulting\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:null,\u0026#34;Product 1 Performance\u0026#34;:null,\u0026#34;Product 2 Name\u0026#34;:null,\u0026#34;Product 2 Performance\u0026#34;:null,\u0026#34;Product 3 Name\u0026#34;:null,\u0026#34;Product 3 Performance\u0026#34;:null,\u0026#34;Product 4 Name\u0026#34;:null,\u0026#34;Product 4 Performance\u0026#34;:null,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:\u0026#34;Gizmo B\u0026#34;,\u0026#34;Product 6 Performance\u0026#34;:64.0,\u0026#34;Product 7 Name\u0026#34;:null,\u0026#34;Product 7 Performance\u0026#34;:null,\u0026#34;Product 8 Name\u0026#34;:\u0026#34;Gizmo D\u0026#34;,\u0026#34;Product 8 Performance\u0026#34;:66.0} -------------------------------------------------- Score: 0.0314980149269104 CompanyName: Nexus Hyper profile: NSW Finance Banking performance: 68.8333333333 json: {\u0026#34;CompanyName\u0026#34;:\u0026#34;Nexus Hyper\u0026#34;,\u0026#34;State\u0026#34;:\u0026#34;NSW\u0026#34;,\u0026#34;Industry\u0026#34;:\u0026#34;Finance\u0026#34;,\u0026#34;Segment\u0026#34;:\u0026#34;Banking\u0026#34;,\u0026#34;Product 1 Name\u0026#34;:\u0026#34;Widget W\u0026#34;,\u0026#34;Product 1 Performance\u0026#34;:49.0,\u0026#34;Product 2 Name\u0026#34;:\u0026#34;Widget X\u0026#34;,\u0026#34;Product 2 Performance\u0026#34;:85.0,\u0026#34;Product 3 Name\u0026#34;:\u0026#34;Widget Y\u0026#34;,\u0026#34;Product 3 Performance\u0026#34;:92.0,\u0026#34;Product 4 Name\u0026#34;:\u0026#34;Widget Z\u0026#34;,\u0026#34;Product 4 Performance\u0026#34;:15.0,\u0026#34;Product 5 Name\u0026#34;:null,\u0026#34;Product 5 Performance\u0026#34;:null,\u0026#34;Product 6 Name\u0026#34;:\u0026#34;Gizmo B\u0026#34;,\u0026#34;Product 6 Performance\u0026#34;:93.0,\u0026#34;Product 7 Name\u0026#34;:\u0026#34;Gizmo C\u0026#34;,\u0026#34;Product 7 Performance\u0026#34;:79.0,\u0026#34;Product 8 Name\u0026#34;:null,\u0026#34;Product 8 Performance\u0026#34;:null} As you can see all of the usual suspects are there, but the scores are different. This is because the hybrid search is using both the full text search and the vector search to return the results. This is a good sign that the hybrid search is working as expected.\nAs you can see for our use case, it doesn\u0026rsquo;t really matter which search type we use, as they all return very similar results. But for your use case, you might find that one search type is better than the other.\nMake recommendations using Azure Open AI Now we are finally at the last part of the notebook. This part of the code will use Azure Open AI to make recommendations based on the high performing products of the customer. In the code above, as part of the print the results to output, we filled up an array called comp_profiles with the JSON strings of the top 20 similar customer profiles. We will use this array to make recommendations.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ### Create AOAI Client ### chat_client = AzureOpenAI( api_key = azure_openai_key, api_version=azure_openai_api_version, azure_endpoint = azure_openai_endpoint ) # Prepare the message content with the company profiles message_content = \u0026#34;You are an assistant that recommends products to companies.\\nYou will receive a company profile and you need to recommend the next product that the company should buy.\\nBelow are some examples of similar companies and their products. Use the below to recommend the next products that the company should buy.\\n\\n\u0026#34; for i, profile in enumerate(comp_profiles, start=1): message_content += f\u0026#34;### Company {i}\\n{profile}\\n\\n\u0026#34; message_content += \u0026#34;Recommend the next product that the company should buy using data exclusively from the above text. Take a step-by-step approach in your response, cite product performance examples from the provided data and give reasoning before sharing final answer.\u0026#34; # Send a chat call to generate an answer response = chat_client.chat.completions.create( model=azure_openai_chat_deployment, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: message_content}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: target_company} ] ) print(response.choices[0].message.content) The things that has the most impact on the recommendations are the message_content and the target_company. The message_content is the system message where we are telling the Azure Open AI model what we want it to do. I have tried to use some good prompt engineering techniques including System message, Start with clear instructions, Repeat instructions at the end, Chain of thought prompting and Provide grounding context to get the best results. All of these techniques and more are explained in more detail here.\nThe way that this piece of code connects to the previous pieces is that I am adding in those top 20 search results from our search index to the message_content. So I have given the Azure Open AI model some context to work with.\nAnd this is the response I got from the Azure Open AI model;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 To recommend the next product Madeup Inc should buy, let\u0026#39;s analyze the data and consider the following factors: 1. **Current Products and Performance**: - Madeup Inc already has \u0026#34;Widget W\u0026#34; with a performance of 85. - They also have \u0026#34;Widget Y\u0026#34; with a performance of 74. 2. **Identify High-Performing Products in Similar Companies**: - For companies in the same industry, segment, and state (NSW, Finance, Banking), we can look at the highly performing products: - **\u0026#34;Widget Z\u0026#34;** has high performance across various companies: - Example: Sky Robotics: \u0026#34;Widget Z\u0026#34; (21); Dynamics Arcadia: \u0026#34;Widget Z\u0026#34; (90); Nexus Hyper: \u0026#34;Widget Z\u0026#34; (15); Consulting Apex: \u0026#34;Widget Z\u0026#34; (81); - with higher performance of 81 to 90 - **\u0026#34;Widget X\u0026#34;** also shows high performance in companies where it\u0026#39;s being effectively utilized: - Example: Helix Industries: \u0026#34;Widget X\u0026#34; (68); Communications Ignite: \u0026#34;Widget X\u0026#34; (76); Sea Sphere: \u0026#34;Widget X\u0026#34; (67) 3. **Look for Consistently High Performance or Complements**: - Based on the products already in use and their performance, adding a product with consistent high performance would benefit the overall system. - Considering the consistent performance of \u0026#34;Widget Z\u0026#34; around 90 in both Nexus Hyper and Diamond Titanium suggests that this could be a viable next option. ### Reasoning for Recommendation: 1. **Widget Z** has shown high performance in similar companies: - For example, Dynamics Arcadia has \u0026#34;Widget Z\u0026#34; performing at 90, and Consulting Apex has it performing at 81. Given that \u0026#34;Widget Z\u0026#34; performs well in the same segment and industry, it is likely to complement the existing products of Madeup Inc. 2. **Widget X** also is a viable option based on performance ranges between 67 to 76 in companies with similar profiles and segments. ### Final Recommendation: **Next Product: \u0026#34;Widget Z\u0026#34;** - **Reason:** - High performance in multiple similar companies within the same segment and industry. - Complements the existing high-performance products already in use by Madeup Inc. By choosing \u0026#34;Widget Z,\u0026#34; Madeup Inc is likely to enhance its system efficiency and overall performance. And as you can see, the Azure Open AI model has done a good job at making recommendations based on the high performing products of the customer. It has also given a good reasoning for the recommendation and has cited product performance examples from the provided data. It looks like it was a close race between Widget Z and Widget X, but Widget Z won out in the end.\nI do like the way that that Azure Open AI 4o has laid out it\u0026rsquo;s reasoning and final recommendation. It\u0026rsquo;s a good way to present the information to the user.\nAlso one of the interesting things with generative ai is that you can run the same code multiple times and get different results, like below;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 To recommend the next product that \u0026#34;Madeup Inc\u0026#34; should buy, we\u0026#39;ll consider the provided data and performance metrics for similar companies in the same segment (Banking) and geographical region (NSW). Here are the steps we will take: ### Step 1: Identify Relevant Companies We\u0026#39;ll focus on companies in the banking segment within NSW that have similar product usage. Relevant companies include: 1. **Sky Robotics** 2. **Consulting Apex** 3. **Dynamics Arcadia** 4. **Nexus Hyper** 5. **Diamond Titanium** ### Step 2: Analyze Product Performance We\u0026#39;ll evaluate the performance of products used by these companies to identify the next suitable product for Madeup Inc. 1. **Widget X:** - Sky Robotics: 87.0 - Nexus Hyper: 85.0 - Hexagon Ignite: 94.0 - Consulting Apex: 58.0 - Diamond Titanium: (No Data) - **Average Performance: (87+85+94+58)/4 = 81.0** 2. **Widget Z:** - Sky Robotics: 21.0 - Dynamics Arcadia: 90.0 - Nexus Hyper: 15.0 - Consulting Apex: 81.0 - Diamond Titanium: 87.0 - **Average Performance: (21+90+15+81+87)/5 = 58.8** 3. **Gizmo D:** - Sky Robotics: 62.0 - Consulting Apex: 49.0 - Dynamics Arcadia: (No Data) - Nexus Hyper: (No Data) - Diamond Titanium: (No Data) - **Average Performance: (62+49)/2 = 55.5** 4. **Gizmo C:** - Dynamics Arcadia: 62.0 - Nexus Hyper: 79.0 - Consulting Apex: 56.0 - Diamond Titanium: (No Data) - **Average Performance: (62+79+56)/3 = 65.7** ### Step 3: Determine the Best Next Product Since Madeup Inc is in the banking segment within NSW and has used Widget W and Widget Y with reasonable performance: - Widget W: 85.0 - Widget Y: 74.0 The statistics show that **Widget X** is the next best-performing product with a consistent high average performance of around **81.0**. ### Recommendation **Widget X** is the most suitable next product for Madeup Inc, considering its high average performance across similar banking companies in NSW, and its successful track record in similar companies. **Final Answer: Widget X** I really like the second response more then the first. So my next job will be to try and get a repeatable response I am happy with from Azure Open AI model.\nSo I have changed the second half of my prompt to be \u0026ldquo;Recommend the next product that the company should buy using data exclusively from the above text. You process should involve a step-by-step approach, which the following steps: 1. Analyze the company profile, 2. Identify Relevant Companies, 3. Calculate Average Performance, 4. Recommend two products a primary and secondary, 5. Justify primary and secondary Recommendations.\u0026rdquo;\nThe major changes I have made is to swap out the chain of thought technique for a break the task down technique. I have also added in a secondary recommendation, as I think that is a good idea. Lastly I added in a step to calculate the average performance of the products, to give more justification to the recommendations.\nAnd this is the response I got from the Azure Open AI model;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 To recommend the next product for Madeup Inc, I\u0026#39;ll follow the outlined steps. ### Step 1: Analyze the company profile **Company Name:** Madeup Inc **Location:** NSW **Industry:** Finance **Segment:** Banking **Current Products and Performance:** - **Widget W:** 85.0 - **Widget Y:** 74.0 ### Step 2: Identify Relevant Companies Since Madeup Inc is in the Finance industry, Banking segment, located in NSW, I\u0026#39;ll look for other NSW-based Banking companies within the dataset. Relevant companies: 1. Sky Robotics 2. Consulting Apex 3. Nexus Hyper 4. Diamond Titanium 5. Dynamics Arcadia ### Step 3: Calculate Average Performance Among the relevant companies, assess the performance of the products they use: #### Widget X - Sky Robotics: 87.0 - Nexus Hyper: 85.0 - Average: (87.0 + 85.0) / 2 = 86.0 #### Widget Z - Sky Robotics: 21.0 - Consulting Apex: 81.0 - Nexus Hyper: 15.0 - Dynamics Arcadia: 90.0 - Diamond Titanium: 87.0 - Average: (21.0 + 81.0 + 15.0 + 90.0 + 87.0) / 5 = 58.8 #### Gizmo B - Nexus Hyper: 93.0 - Diamond Titanium: 67.0 - Average: (93.0 + 67.0) / 2 = 80.0 #### Gizmo C - Nexus Hyper: 79.0 - Dynamics Arcadia: 62.0 - Consulting Apex: 56.0 - Average: (79.0 + 62.0 + 56.0) / 3 = 65.7 #### Gizmo D - Sky Robotics: 62.0 - Consulting Apex: 49.0 - Dynamics Arcadia: 0.0 (absent) - Nexus Hyper: 0.0 (absent) - Diamond Titanium: 0.0 (absent) - Average: (62.0 + 49.0) / 2 = 55.5 ### Step 4: Recommend Primary and Secondary Products **Primary Recommendation:** Widget X (Average Performance: 86.0) **Secondary Recommendation:** Gizmo B (Average Performance: 80.0) ### Step 5: Justify Recommendations **Primary Recommendation: Widget X** - **Reasoning:** Widget X shows a consistently high performance average (86.0) in relevant companies such as Sky Robotics and Nexus Hyper. The high average and strong performance suggest it is a reliable product for achieving effective outcomes in the Banking segment within the Finance industry. **Secondary Recommendation: Gizmo B** - **Reasoning:** Gizmo B also shows good performance with an average of 80.0, as seen in companies like Nexus Hyper and Diamond Titanium. This makes it a strong contender for providing additional benefits and complementing the existing high performance of Widget W and Widget Y. Hence, based on the performance data and relevance within the industry and geographical segment, Widget X and Gizmo B are the recommended next products for Madeup Inc. I also ran the prompt again 5 more times (which we can do now we have setup our Azure environment) and got consistent results with Wiget X and Gizmo B always being recommended. So I am happy with the results.\nConclusion In this part two post, we have expanded our dataset and created a search index on Azure AI Search. We have also queried the search index using full text search, vector search and hybrid search and We have also made recommendations using Azure Open AI.\nI hope you have found this post useful and that it has inspired you to build your own Gen AI Product Recommendation System. If you have any questions or comments, please feel free to leave them below. I would love to hear from you.\n","date":"2024-09-05T10:49:01+10:00","image":"https://mfblog.au/p/part-2-simple-gen-ai-product-recommendation-system/cover_hu7477463577929926113.jpg","permalink":"https://mfblog.au/p/part-2-simple-gen-ai-product-recommendation-system/","title":"Part 2 - Simple Gen AI Product Recommendation System"},{"content":" I am a Microsoft employee, but the views expressed here are mine and not those of my employer.\nI have been working with some clients recently on proof-of-concepts (POC) to recommend products to their customers. I have found that generative AI techniques can be very effective and in this post, I will show you how to build a simple Gen AI Product Recommendation System that you can use to quickly develop a proof-of-concept (POC) for your clients.\nThe idea behind this post is to just use Python, a CSV file (containing customer and product performance) and Azure Open AI to build a simple Gen AI Product Recommendation System \u0026#x1f603;\nAgain this process is just for quickly POCing the concept and will be part one of a series of posts I will be writing on this topic. Which eventually will include more advanced techniques and technologies and lead to a production-ready system using techniques like Retrieval Augmented Generation (RAG) and more \u0026#x1f605;\nTLDR If you just want to see the code, you can find it here\nAll you need is a CSV file with customer and product performance data and an Azure Open AI account. Then you can use the python code above to POC the concept. A sample CSV file has been included in the GitHub repo.\nSo as long as you can get customer and product performance out of your system, you can POC a Gen AI Product Recommendation System \u0026#x1f44d;\nPrerequisites There are only two prerequisites to follow along with this post;\nAn Azure subscription and access to Azure Open AI. For the Azure Open AI component I use the text-embedding-ada-002 model to vectorise the CSV file (more details on this later) and the question. I also use the GPT-4o model to recommend the next best product to the customer. You can sign up for Azure Open AI here \u0026#x1f4d6; Note: You do not have to use Azure Open AI to make this work. You can sub in other AI models to perform the same functions as I have done in this post.\nA CSV file with customer and product performance data. I have included a sample CSV file in the GitHub repo for you to use and will go into more detail about the CSV file below. Introduction The python code found here is a simple Gen AI Product Recommendation System that uses generative AI techniques to recommend products to customers. The system is designed for rapid proof-of-concept (POC) development and can be used to quickly develop a POC for your clients. The code flows as follows;\nPrepare the data Vectorise the CSV file using Azure Open AI Vectorise your target customers profile and return similar customers Refine the list of similar customers with customers that have good product performance Recommend the next best product to the customer using Azure Open AI Prepare the data The first step is to prepare the data. I used a combination of ChatGPT and RAND functions in excel to create sample data. You should use your own data for this step. The data should be in a CSV file with similar columns to the below;\nCompany Name, State, Industry, Segment, Product 1 Name, Product 1 Performance, Product 2 Name, Product 2 Performance, Product 3 Name, Product 3 Performance, Product 4 Name,Product 4 Performance, Product 5 Name, Product 5 Performance, Product 6 Name, Product 6 Performance, Product 7 Name, Product 7 Performance, Product 8 Name, Product 8 Performance\nIn my example, I am recommending products to companies. You can see with headers like Company Name, State, Industry, Segment I am tring to capture the profiles of companies. You can change these headers to suit your needs. I.e. if you are recommending products to individuals you may remove the Industry column an replace it with something else.\nI chose to have 8 products in my example to make it more interesting. You might have more or less products, which is ok and the concept will still work.\nThe performance column is a number between 0 and 100. 0 being the worst performing product and 100 being the best performing product. You can change this to suit your needs.\n\u0026#x1f4d6; Note: Your performance column could be a dollar value or a percentage or range from -100 to 10,000. It\u0026rsquo;s completely up to you.\nVectorise the CSV file using Azure Open AI Now we have our CSV file, we need to vectorise it. This is where Azure Open AI comes in. I use the text-embedding-ada-002 model to vectorise the CSV file. This model is a transformer-based model that can convert text into vectors.\nI have being using the word vectorise pretty liberally in this post. What I really mean is to create embeddings of the text. If you are interested in digging into this deeper, please follow this link here.\n\u0026#x1f4d6; Note: I will not be covering chunking strategies in this post. But you can read more about them here. In my experience when working with CSV files, you want a single customers data on one line. As this will make the chunking strategy easier, as it becomes one embedding per line.\nThe generate_embeddings function has been taken from this sample here, which I found super useful to kick start this process.\nIf you are following along with th example, your DataFrame should now look like the below; if you uncomment the print statement at line 48 and run the code.\n1 2 3 4 5 6 7 8 9 10 11 12 13 Company Name State Industry ... comb n_tokens ada_v2 0 Aether Alytics NSW Technology ... Aether Alytics NSW Technology Software Widget ... 35 [0.006774003151804209, 0.014850836247205734, -... 1 Aether Dymics QLD Healthcare ... Aether Dymics QLD Healthcare Services Widg... 31 [0.0005342101794667542, 0.023639481514692307, ... 2 Aether Innovate VIC Fince ... Aether Innovate VIC Fince Banking Widget W 93.... 29 [-0.00746396416798234, -0.001040163915604353, ... 3 Aether Nexus NSW Manufacturing ... Aether Nexus NSW Manufacturing Electronics W... 40 [0.00921355839818716, 0.013308473862707615, -0... 4 AetherCraft Innovations QLD Technology ... AetherCraft Innovations QLD Technology Service... 42 [0.004110227804630995, 0.012736016884446144, -... .. ... ... ... ... ... ... ... 95 Vertex Ventures VIC Retail ... Vertex Ventures VIC Retail Sporting Goods Wi... 35 [0.0020639034919440746, -0.0007355211419053376... 96 Zenith Dymics QLD Healthcare ... Zenith Dymics QLD Healthcare Aged Care W... 39 [0.011205820366740227, 0.01472207996994257, -0... 97 Zenith Innovations VIC Manufacturing ... Zenith Innovations VIC Manufacturing Electroni... 53 [0.00700162211433053, 0.006710764020681381, -0... 98 Zenith Ventures NSW Retail ... Zenith Ventures NSW Retail Supermarket Widge... 35 [0.01493804156780243, -0.005660619121044874, -... 99 Zenith Zephyr NSW Fince ... Zenith Zephyr NSW Fince Superannuation Widge... 52 [0.003903178498148918, 0.010286277160048485, -... As you can see above, we have a a couple of new columns; comb, n-tokens and ada_v2.\nThe comb column is a combination of the all of the columns in the CSV, which is defined in the cols variable in line 22 of the Python code. This is the data we will use to find similar companies to our target company.\n\u0026#x1f4d6; Note: I have included all of the column data in comb column, which you may not what to do. This is the data that will been turned into our embeddings and used to find similar company profiles. Feel free to experiment and play around which which columns make sense to define as company profile data.\nThe n-tokens column contains the number of tokens in the comb column. This is part of the sample code here which I thought would be good to include, so we can see hoe many tokens are in each company profile.\nThe ada-v2 column contains the embeddings of the text in the comb column. This is what we will use to find similar companies to our target company.\nVectorise your target customers profile and return similar customers Now we have our CSV file vectorised, we can vectorise our target companies profile and return similar companies. The search_docs function does this. It takes the target companies profile and the vectorised CSV file and returns the most similar companies to the target company.\nAgain the *search_docs function has been taken from this sample here, which I found super useful to kick start this process.\nOne thing I did change was the number of similar companies returned. I found that 4 wasn\u0026rsquo;t enough to demonstrate the concept. So I increased it to 20. You can change this to suit your needs.\nOur target company profile is Madeup Inc NSW Finance Banking Widget W 85 Widget Y 74. So to expand on this, the name of the company is Madeup Inc, they are located in NSW, their industry is Finance, their segment is Banking and they have purchased Widget W and Widget Y with performance scores of 85 and 74 respectively.\nIf you are following along with the example and run the code, we have created a DataFrame called res and it should look like the below; if you uncomment the print statement at line 79 and run the code.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [20 rows x 25 columns] Company Name State Industry Segment ... comb n_tokens ada_v2 similarities 94 Vertex Innovations NSW Fince Banking ... Vertex Innovations NSW Fince Banking Widget ... 34 [-0.013468814082443714, 0.011046885512769222, ... 0.895079 40 Nebula Innovate QLD Fince Banking ... Nebula Innovate QLD Fince Banking Widget W 55.... 43 [-0.009700409136712551, 0.00857381522655487, -... 0.880019 36 Lu Labs WA Fince Banking ... Lu Labs WA Fince Banking Widget W 77.0 Widge... 41 [0.001298676710575819, 0.014152105897665024, 0... 0.877526 16 Celestial Innovators NSW Healthcare Aged Care ... Celestial Innovators NSW Healthcare Aged Care ... 36 [0.02342524565756321, 0.01131583470851183, -0.... 0.873675 99 Zenith Zephyr NSW Fince Superannuation ... Zenith Zephyr NSW Fince Superannuation Widge... 52 [0.003903178498148918, 0.010286277160048485, -... 0.872854 93 TitanCraft Innovations NSW Fince Superannuation ... TitanCraft Innovations NSW Fince Superannuatio... 46 [0.0011813724413514137, 0.0001086916818167083,... 0.872731 50 Nova Innovations NSW Fince Services ... Nova Innovations NSW Fince Services Widget X... 30 [0.008242596872150898, 0.013941271230578423, -... 0.872451 77 Stellar Solutions NSW Technology Services ... Stellar Solutions NSW Technology Services Widg... 41 [0.009536132216453552, 0.01122966781258583, -0... 0.872061 9 Arcane Innovations NSW Technology Services ... Arcane Innovations NSW Technology Services Wid... 34 [0.009464128874242306, 0.00965742114931345, -0... 0.869977 21 Electra Innovators NSW Technology Software ... Electra Innovators NSW Technology Software ... 28 [-0.005648091435432434, -0.001541689271107316,... 0.869639 98 Zenith Ventures NSW Retail Supermarket ... Zenith Ventures NSW Retail Supermarket Widge... 35 [0.01493804156780243, -0.005660619121044874, -... 0.869488 86 TerraNova Solutions QLD Fince Banking ... TerraNova Solutions QLD Fince Banking Widget W... 49 [0.0007926894468255341, 0.008511657826602459, ... 0.868256 82 Synergy Solutions VIC Retail Fashion ... Synergy Solutions VIC Retail Fashion Widget W ... 31 [1.3071230569039471e-05, -0.016084423288702965... 0.868212 66 Quantum Innovations VIC Fince Banking ... Quantum Innovations VIC Fince Banking Widget W... 36 [-0.0017555200029164553, 0.0030148178339004517... 0.867936 2 Aether Innovate VIC Fince Banking ... Aether Innovate VIC Fince Banking Widget W 93.... 29 [-0.006697694770991802, -0.0010367195354774594... 0.866954 58 Orion Ventures NSW Technology Services ... Orion Ventures NSW Technology Services Widge... 35 [0.01005646027624607, -0.0012994403950870037, ... 0.865864 73 Solaris Innovations QLD Fince Superannuation ... Solaris Innovations QLD Fince Superannuation ... 40 [0.015805836766958237, 0.010568874888122082, 0... 0.865290 75 Solaris Synergy VIC Fince Banking ... Solaris Synergy VIC Fince Banking Widget X 8... 35 [0.001066106022335589, -0.00687881326302886, 0... 0.862809 25 Helios Innovate NSW Retail Fashion ... Helios Innovate NSW Retail Fashion Widget X ... 23 [0.008114686235785484, 0.014257645234465599, -... 0.861633 20 Electra Innovate NSW Manufacturing Textiles ... Electra Innovate NSW Manufacturing Textiles Wi... 28 [-0.003946746699512005, 0.008698659017682076, ... 0.861492 As you can see above, we now have a DataFrame called res which contains 20 similar companies to our target company. The similarities column contains the cosine similarity between the target company and the similar companies. The higher the cosine similarity, the more similar the companies are.\nRefine the list of similar customers with customers that have good product performance Next I want to refine this list to only include companies that have a similarities over 0.87, as I only want to find companies that are very similar to the target customer. So in you uncomment the print statement at line 85 and run the code, you will see the DataFrame res has been refined to only include companies with a similarities over 0.87.\n1 2 3 4 5 6 7 8 9 10 Company Name State Industry Segment ... comb n_tokens ada_v2 similarities 94 Vertex Innovations NSW Fince Banking ... Vertex Innovations NSW Fince Banking Widget ... 34 [-0.013468814082443714, 0.011046885512769222, ... 0.895079 40 Nebula Innovate QLD Fince Banking ... Nebula Innovate QLD Fince Banking Widget W 55.... 43 [-0.009700409136712551, 0.00857381522655487, -... 0.880019 36 Lu Labs WA Fince Banking ... Lu Labs WA Fince Banking Widget W 77.0 Widge... 41 [0.001298676710575819, 0.014152105897665024, 0... 0.877526 16 Celestial Innovators NSW Healthcare Aged Care ... Celestial Innovators NSW Healthcare Aged Care ... 36 [0.02342524565756321, 0.01131583470851183, -0.... 0.873675 99 Zenith Zephyr NSW Fince Superannuation ... Zenith Zephyr NSW Fince Superannuation Widge... 52 [0.003903178498148918, 0.010286277160048485, -... 0.872854 93 TitanCraft Innovations NSW Fince Superannuation ... TitanCraft Innovations NSW Fince Superannuatio... 46 [0.0011813724413514137, 0.0001086916818167083,... 0.872731 50 Nova Innovations NSW Fince Services ... Nova Innovations NSW Fince Services Widget X... 30 [0.008242596872150898, 0.013941271230578423, -... 0.872451 77 Stellar Solutions NSW Technology Services ... Stellar Solutions NSW Technology Services Widg... 41 [0.009536132216453552, 0.01122966781258583, -0... 0.872061 As you can see above, we are left with 8 company profiles. 6 of these companies are in the same Industry as the target company and 3 are even in same segment. Also 6 are in the same State.\nNext we again want to refine this list to only include companies that have good product performance. So I have taken a rudimentary approach to giving each of these 8 companies a score based on their product performance, simply by taking the mean of their product performance. Then I have removed all companies with a score under 70. If you uncomment the print statement at line 103 and run the code, you will see the DataFrame res has been refined to only include companies with a product performance score over 70.\n1 2 3 4 5 6 Company Name State Industry Segment ... n_tokens ada_v2 similarities performance 94 Vertex Innovations NSW Fince Banking ... 34 [-0.013468814082443714, 0.011046885512769222, ... 0.895079 72.5 99 Zenith Zephyr NSW Fince Superannuation ... 52 [0.003903178498148918, 0.010286277160048485, -... 0.872854 72.0 93 TitanCraft Innovations NSW Fince Superannuation ... 46 [0.0011813724413514137, 0.0001086916818167083,... 0.872731 76.0 77 Stellar Solutions NSW Technology Services ... 41 [0.009536132216453552, 0.01122966781258583, -0... 0.872061 73.0 As you can see above, we are left with 4 company profiles. 3 of these companies are in the same Industry as the target company and all 4 are in the same State.\n\u0026#x1f4d6; Note: Again, not sure if 4 or 6 or 10 or 20 profiles will yield the best results. But for demonstration purposes, I am happy to stick with 4. You may choose a higher number is you like \u0026#x1f603;\nRecommend the next best product to the customer using Azure Open AI Finally, we can recommend the next best product to the company using Azure Open AI. I use the GPT-4o model to recommend the next best product to the company.\nThe way I do this is I create a system prompt that has the following instructions;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 You are a assistant that recommends products to companies. You will receive a company profile and you need to recommend the next product that the company should buy. Below are some examples of similar companies and their products. Use the below to recommend the next products that the company should buy. ### Example Company 1 $comp_prof_1 ### Example Company 2 $comp_prof_2 ### Example Company 3 $comp_prof_3 ### Example Company 4\\n $comp_prof_4 Recommend the next one product only that the company should buy. Then on a separate line write a short concise reason why they should buy the product along with insights contained in the data. I am using some good prompt engineering practises here, but the key thing is to include the company profiles in the prompt. This way the GPT-4o model can use the company profiles to recommend the next best product to the Madeup Inc. Also I am asking it to recommend only one product, as I am only interested in the next best product for Madeup Inc. If you would like to see all the products that the similar companies have bought, you can change this prompt to suit your needs.\nAnd lastly, below is the recommendation that the GPT-4o model has made for Madeup Inc;\n1 2 3 **Recommended Product: Widget Z** **Reason:** Widget Z has consistently high performance in the banking segment, with performance scores such as 94 from Vertex Innovations. Adding Widget Z could bolster Madeup Incs product lineup and improve their overall offerings. As you can see above, the GPT-4o model has recommended Widget Z to Madeup Inc. The reason being that Widget Z has consistently high performance in the banking segment, with performance scores such as 94 from Vertex Innovations. Adding Widget Z could bolster Madeup Incs product lineup and improve their overall offerings.\nConclusion In this post, I have shown you how to build a simple Gen AI Product Recommendation System that you can use to quickly develop a proof-of-concept (POC) for your clients. The system uses generative AI techniques to recommend products to customers and is designed for rapid POC development. The system is built using Python, a CSV file (containing customer and product performance) and Azure Open AI. The system can be used to quickly develop a POC for your clients and can be easily adapted to suit your needs.\n\u0026#x1f4d6; Note: This is just a simple example to get you started. In future posts, I will be covering more advanced techniques and technologies to build a production-ready Gen AI Product Recommendation System. For example, this process stores all of the vectors and CSV data in memory. This is ok for POCs but certainly not Production or even MVPs. You would need to store this data in a vector database or search technology and use various different techniques to retrieve similar company profiles. I will cover this in a future post.\nI hope you have found this post useful and that it has inspired you to build your own Gen AI Product Recommendation System. If you have any questions or comments, please feel free to leave them below. I would love to hear from you.\n","date":"2024-06-20T14:28:16+10:00","image":"https://mfblog.au/p/simple-gen-ai-product-recommendation-system-you-can-poc-quickly/cover_hu16849642070609214732.jpg","permalink":"https://mfblog.au/p/simple-gen-ai-product-recommendation-system-you-can-poc-quickly/","title":"Simple Gen AI Product Recommendation System you can POC quickly"},{"content":" I am a Microsoft employee, but the views expressed here are mine and not those of my employer.\nI have been working with some clients recently on projects to automate the processing of financial documents. The goal is to extract key information from these documents and then use that information to perform some analysis. The analysis could be anything from fraud detection, risk assessment, summarization, classification, etc.\nThe idea behind this post is to show you how to build a simple document processing pipeline using Azure AI Document Intelligence and Azure Open AI. We will use Azure Document Intelligence to extract key information from the documents and then use Azure Open AI to perform fraud detection on the extracted information.\nTLDR Microsoft already has a defined architecture for automating document processing by using Azure AI Document Intelligence here - Automate document processing by using Azure Form Recognizer and above :) Azure AI Document Intelligence is the new name for Azure Form Recognizer. Azure AI Document Intelligence is an AI service that applies advanced machine learning to extract text, key-value pairs, tables, and structures from documents automatically and accurately. I have created a working example of how to use Azure AI Document Intelligence, Azure Open AI, Azure Functions and Python to process financial documents in this GitHub repo. This process can preform fraud detection process on the extracted information from the documents. Introduction The sample I have created will focus on Extraction and Enrichment sections of the above diagram, centred around a financial company who needs to process online applications that have Invoices and Receipts as part of the application process. Please see my diagram below for a high-level overview of the process.\nCustomers use the financial company\u0026rsquo;s application to apply for a rebate/loan. The application has been coded in Python with Gradio to create a quick user interface. The application form data is sent to Azure CosmosDB for storage. The Invoice and Receipt are sent to Azure Blob Storage. An Azure Function is triggered by the new documents in the Blob Storage container and sends the documents to Azure AI Document Intelligence for processing. The function uses the pre-built Invoice and Receipt model. Azure AI Document Intelligence process the Invoice and Receipt and sends the extracted information to Azure CosmosDB for storage. An Azure Function is trigger and sends the Invoice and Receipt data to Azure Open AI for fraud detection. The results are sent to Azure CosmosDB for storage. The Invoice and Receipt documents are moved to a new container in Azure Blob Storage called processed. 1. Rebate/Loan Application The application has been coded in Python with Gradio to create a quick user interface. Applicants can fill in their details and attach an invoice and receipt to start the process. The application form data is sent to Azure CosmosDB for storage. The code for this can be found in this GitHub Repo.\n2. Azure CosmosDB This is a vanilla Azure CosmosDB setup where I just accepted the defaults. I have created a database called ToDoItems and two containers called docs and leases.\nSide Note: I only used ToDoItems and docs and the database and container names because I was following a quick start guide. You should use more meaningful names for your project.\nThe leases container was created so I can use the Change Feed Processor to trigger the Azure Function when new documents are added to the Invoice and Receipt containers.\n3. Azure Blob Storage I have created two containers in Azure Blob Storage called docs and processed. The Invoice and Receipt documents are sent to the invoice and receipt containers respectively. When Invoice and Receipt documents have been processed, they are moved to a new container in Azure Blob Storage called processed.\n4. Azure Functions I have created three Azure Functions, one for invoices and receipts and one for fraud detection. The invoice and receipt function is triggered by the new documents in the invoice and receipt containers respectively. The functions sends the documents to Azure AI Document Intelligence for processing and results are sent to Azure CosmosDB for storage.\nThe code for all of these functions can be found in this GitHub Repo.\nSide Note: I used the Function v2 model for Python, which uses the new decorator model. I found it easier to use than the old model and loved having all three functions and there triggers in the same file.\n5. Azure AI Document Intelligence I am using the pre-built Invoice and Receipt models that are available in Azure AI Document Intelligence for this sample project, because they fit my needs. If you have other types of documents, you can create your own custom models.\nThere is a great article here which takes you everything you need to know about customer models. There is an extract below;\nCustom models now include custom classification models for scenarios where you need to identify the document type prior to invoking the extraction model. Classifier models are available starting with the 2023-07-31 (GA) API. A classification model can be paired with a custom extraction model to analyze and extract fields from forms and documents specific to your business to create a document processing solution. Standalone custom extraction models can be combined to create composed models.\nIn my example, Azure AI Document Intelligence receives an API call from the Azure Function and sends the document to the pre-built Invoice or Receipt model for processing. The results are sent to Azure CosmosDB for storage.\nI also store the confidence score of the extraction in the CosmosDB. This is important because I want to know how confident the model is in the extraction. If the confidence score is low, I may want to send the document to a human for review.\nI also store the content JSON response from the Azure AI Document Intelligence API in the CosmosDB. This will be useful for the enrichment process :)\n6. Azure Open AI Now where does Azure Open AI come into this? Azure Open AI and generative AI can do many many things and there are many use cases for it within the financial industry. For my example, I chosen to create a fraud detection process.\nNow this process is not designed to replace the human process, or the humans involved in fraud detection. It is design to make it easier for humans to do their job. I.e. flag certain applications as potentially fraudulent, record why Azure Open AI thinks it\u0026rsquo;s fraudulent and then have a human review them.\nI have created a separate Azure Function for fraud detection. This function is triggered when a CosmosDB record (an application) has had both their Invoice and Receipt processed by Azure AI Document Intelligence. The function then sends the Invoice and Receipt data to Azure Open AI for fraud detection. The results are sent to Azure CosmosDB for storage.\nFor example, below is screen shot of a record in the CosmosDB. The comparison field is the result of the fraud detection process.\nI have pasted below the full text below;\n\u0026ldquo;The invoice and receipt do match. Here are the reasons why they match:\nBoth the invoice and receipt are from the same company, Contoso Ltd., and share the same company address and phone number. The invoice and receipt have the same total amount due, $2624.99. Both documents list the same quantity and description of items sold: 20 Solar Panels. The itemized prices match, with a unit price of $130 and a total price for the items being $2600.00. Shipping and handling costs are the same on both documents, $24.99. The invoice and receipt both reflect no sales tax being added. The receipt acknowledges payment being made via a credit card, which implies that the amount due on the invoice has been settled. The salesperson\u0026rsquo;s name, Suman, is mentioned on both the invoice and receipt, supporting their correlation. Thus, the matching details on both documents confirm that the invoice and receipt correspond to the same transaction.\u0026rdquo;\nThe example is from a legitimate submission where the invoice and receipt do match. So if I was a claims processor, I would be happy to see this response and this would provide me with the confidence to approve the application.\nI am using the Azure Open AI completion endpoint and the system prompt I am using in my Azure Open AI request is;\nYou are an AI assistant that helps audit invoices and receipts to make sure match. If the invoice and receipt do not match, state they do not match. Then explain the reasons why they do not match in bullet point form. If the invoice and receipt do match, state they match. Then explain the reasons why they do match in bullet point form.\nBringing it all together From the perspective of the financial company, I have created another UI in Gradio and the code can be found in this GitHub Repo called processor demo. This UI allows the financial company to view the applications that have been submitted and the results of the fraud detection process, as below;\nThe claims processor can lookup a application number and view the details of the application. They can see the full extracted data from both the Invoice and Receipt, and the results of the fraud detection process in the comparison field.\nThis will allow the claims processor to make an informed decision on whether to approve or reject the application.\nFor bonus points, because I also have the processed documents URI stored in CosmosDB, I could also display the invoice and receipt in the Gradio UI, so as the claims processor is reading the comparison commentary produced by Azure Open AI, they can view the documents side by side.\nConclusion I hope this post has given you an insight into how you can use Azure AI Document Intelligence and Azure Open AI to automate the processing of financial documents. The sample I have created is just a starting point and there are many other use cases for these services.\n","date":"2024-03-24T15:23:32+11:00","image":"https://mfblog.au/p/automated-document-processing-and-fraud-detection-with-azure/cover_hu6734534748483404421.jpg","permalink":"https://mfblog.au/p/automated-document-processing-and-fraud-detection-with-azure/","title":"Automated document processing and fraud detection with Azure"},{"content":" I am a Microsoft employee, but the views expressed here are mine and not those of my employer.\nI have been working with some clients that are new to Azure Open AI and they have been asking me about how to increase performance and reduce per call latency within the service. Usually I would talk them through this Microsoft article. But I thought I would go one step further with this article and use Python and test calls demonstrate the performance and latency of Azure Open AI.\nTLDR If the performance and per call latency in Azure Open AI is not meeting you expectations, then make these changes, if possible in this order\nIf you are creating a Chat bot or chat experience, enable stream mode in the call. Use the latest models in the GPT-3.5 Turbo model series. Reduce the amount of completion tokens in the model response. Use the max_tokens and stop parameters in the call. Streaming The below is taken from https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/latency#streaming;\n\u0026ldquo;Setting stream: true in a request makes the service return tokens as soon as they\u0026rsquo;re available, instead of waiting for the full sequence of tokens to be generated. It doesn\u0026rsquo;t change the time to get all the tokens, but it reduces the time for first response. This approach provides a better user experience since end-users can read the response as it is generated.\u0026rdquo;\nI didn\u0026rsquo;t think there was a need to test this. As I think the premise is sound and there are lots of examples where this provides a great user experience. I.e. ChatGPT.\nTesting setup The other 3 items in the TLDR we are going to test.\nWe will be completing all of the test against Azure Open AI completions endpoint. All of the test were conducted with the following;\nAll tests were run on a VM deployed into the Australia East region. The Azure Open AI service was deployed to the Australia East region. The code that was used to create the tests can be found here. The Python code was run as part of a cronjob on the VM. I modified the crontab file and add a new line like this; * * * * * /usr/bin/python3 /home/fredderf204/aoai-tester/app.py \u0026gt;\u0026gt; /home/fredderf204/aoai-tester/aoai-tester.log 2\u0026gt;\u0026amp;1. This means that the test will run every 1 minute and the output (both STDOUT and STDERR) will be written to a log file. I collected the data from the log file and put it into a spreadsheet. Another way to monitor per call latency I will be writing the results of my python code to a log file on the VM. I did this because I thought it would be a good way to record and measure the results.\nBut there is another way to monitor per call latency, and it\u0026rsquo;s with Azure Monitor. This article goes into detail about how to do this. And the TLDR is that you can simply run your code against Azure Open AI and see the per call latency by clicking \u0026ldquo;Metrics\u0026rdquo; in the Azure Portal under the Monitoring section. Then select the latency metric and you will see something like this;\nYou can further filter by deployment, or api version, or endpoint. But to be honest, the only reason I didn\u0026rsquo;t do this was because I didn\u0026rsquo;t know how to get the data into excel to create the graphs. But I am sure there is a way.\nTest 1 - Use the latest models in the GPT-3.5 Turbo model series The first test will be a per call latency test comparing GPT-4 vs GPT-3.5 Turbo. The general advice I give to my clients is the try GPT-3.5 Turbo model series to see if it meets your needs. If it does not, there try out GPT-4 model series. You will see below that GPT-3.5 Turbo is more performant and has a lower per call latency compared to GPT-4. But GPT-4 is more accurate, so it\u0026rsquo;s a trade off.\nIn the below chart I sent 20 requests to each model and recorded the results. As mentioned previously, I used the code in this repo here and used this prompt write a 500 word short story. I chose this prompt for 2 reasons;\nIt\u0026rsquo;s simple It\u0026rsquo;s going to create a fairly large amount completion tokens. GPT-4 had an average end to end latency of 53.13 seconds and generated an average of 687.55 completion tokens per call.\nGPT-3.5 Turbo had an average end to end latency of 7.77 seconds and generated an average of 756.9 completion tokens per call.\nAs you can see GPT-3.5 Turbo is an order of magnitude faster than GPT-4. If you can switch from GPT-4 to GPT-3.5 Turbo, then you will see a quite an improvement in performance and per call latency. Which is why this is the first recommendation I make to my clients.\nTest 2 - Reduce the amount of completion tokens in the model response For this test, we will take the previous results from GPT-4 and the prompt write a 500 word short story and compare it to the same model but use a modified prompt write a 300 word short story. The only difference between the 2 prompts is the number of words in the story. Which should result in fewer completion tokens being generated.\nAgain we sent 20 calls to the service and recorded the results.\nPrompt 1 (500 word short story) resulted in an average end to end latency of 53.13 seconds and generated an average of 687.55 completion tokens per call.\nPrompt 2 (300 word short story) resulted in an average end to end latency of 25.33 seconds and generated an average of 434.05 completion tokens per call.\nAs you can see, there is a direct correlation between the amount of completion tokens and the end to end latency. The more completion tokens, the longer the end to end latency. So if you can reduce the amount of completion tokens, you will see a reduction in end to end latency.\nThis article goes into more detail about why this is.\nTest 3 - Use the max_tokens and stop parameters For this test, one set of requests will have the max_tokens and stop parameters set and the other will not. We will use a new prompt which is larger and uses 2 shot examples. Both prompts were run against GPT-4. Please see the prompt below;\nwrite a 300 word story that begins with Once upon a time and ends with The End \\n\\nExample 1: Once upon a time, in a faraway land, there lived a young girl named Lila. She was a curious and adventurous girl who loved to explore the world around her. One day, while wandering through the woods, she stumbled upon a hidden cave. The entrance was small, but Lila was determined to explore it. She squeezed through the narrow opening and found herself in a large cavern. The walls were covered in glittering crystals that sparkled in the dim light. Lila was amazed by the beauty of the cave and decided to explore further.\\n\\nAs she walked deeper into the cave, she noticed a faint glow in the distance. She followed the light and soon found herself in a large chamber. In the center of the room was a glowing orb that pulsed with a soft light. Lila approached the orb and reached out to touch it. Suddenly, she was enveloped in a bright light and felt herself being lifted off the ground.\\n\\nWhen the light faded, Lila found herself in a strange new world. The sky was a deep shade of purple, and the trees were made of crystal. She looked around in wonder and realized that she had been transported to a magical realm.\\n\\nLila spent many years exploring this new world, meeting strange creatures and having incredible adventures. But eventually, she grew homesick and decided to return to her own world. She approached the glowing orb once again and was enveloped in a bright light. When the light faded, she found herself back in the cave where she had started.\\n\\nLila emerged from the cave, changed forever by her incredible journey. She went on to live a long and happy life, but she never forgot the magic of that other world. And so, we come to the end of our story. The End.\\n\\nExample 2: Once upon a time, in the kingdom of Uriel, lived an old shoemaker named Bartolo. He was a quiet man who lived a simple life, crafting the most beautiful shoes to earn his livelihood. But Bartolo had a secret - he could weave magic into his shoes, giving them abilities far beyond any regular footwear. And so, Uriel\\'s inhabitants adored his creations, no one knowing Bartolo was actually a wizard in disguise.\\n\\nOne gloomy evening, Bartolo noticed a young girl sobbing outside his shop. Her cloth shoes were ripped and worn, her feet bloodied from the rough city cobblestones. Bartolo\\'s heart squeezed at the sight. He called out to her, promising a pair of new shoes.\\n\\nThe next day, Bartolo presented the girl, Lily, with enchanted dancing shoes. They would protect her feet and lead her heart to happiness. She looked up at Bartolo, her eyes wet with gratitude, and danced away, leaving a trail of soft laughter and twinkling sparkles.\\n\\nWeeks later, a royal proclamation announced a grand ball to choose a prince\\'s bride, and Lily decided to attend. That night, her gifted shoes guided her as she danced with a grace that awoke an otherworldly charm. The prince was instantly smitten by Lily\\'s uniqueness and chose her as his bride.\\n\\nOn their wedding, Bartolo presented a wondrous pair of shoes to Lily as a wedding gift - shoes embedded with everlasting love and compassion. Witnessing Lily\\'s happiness, Bartolo felt his life had been worthwhile. He had used his magic to give joy, and in return, he was filled with contentment.\\n\\nYears later, after living a fulfilled magical life, Bartolo passed away. But through Lily, his magical shoes, and the little happiness they brought to this kingdom, his legacy lived on, forever woven into the fabric of Uriel\\'s tales. Thus, our story concludes, until we meet again under the moonlit pages of another tale. The End.\nFor the second set of calls, we will set the max_token parameter to 450 and stop to The End. This means that the model will stop generating tokens 3 ways;\nWhen it finishes generating the response When it hits the stop sequence of The End. When it reaches 450 tokens completion tokens. This should result in fewer completion tokens being generated.\nCall set 1 (no max_tokens or stop) resulted in an average end to end latency of 38.48 seconds and generated an average of 438.35 completion tokens per call.\nCall set 2 (max_tokens = 450 and stop = The End) resulted in an average end to end latency of 34.55 seconds and generated an average of 426.8 completion tokens per call.\nI know it a little hard to tell in the chart, but there was a slight improvement in end to end latency and a slight reduction in the amount of completion tokens. This is why I would recommend this as the last thing to try. As it\u0026rsquo;s not going to have a huge impact on performance or per call latency in comparison to the other 2 items above.\nLarge prompt tokens have little impact on performance and per call latency Going into this experiment, I though the amount of prompt tokens would have a large impact on performance and per call latency. Turns out that is not the case! I did 1 final test. Against GPT-4 I used our original prompt of write a 500 word short story and ran a test set. Then I used another prompt that started out the same, and I added a random set of 5000 words to the end of the prompt.\nThis resulted in first prompt having 14 prompt tokens and the second prompt having on average 7091 prompt tokens. I ran 20 calls against each prompt and recorded the results.\nCall set 1 (14 prompt tokens) resulted in an average end to end latency of 53.13 seconds and generated an average of 687.55 completion tokens per call. I used the same data as the latest models test.\nCall set 2 (7091 prompt tokens) resulted in an average end to end latency of 53.47 seconds and generated an average of 813.1 completion tokens per call.\nThere seems to be almost no difference in performance or per call latency when using a large amount of prompt tokens. So if you need to use a large amount of prompt tokens, then you should be ok.\nConclusion I would reccomend everyone go and read https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/latency as it has some great information about how to increase performance and reduce per call latency in Azure Open AI. Which we have just proved with Python in our simple experiments.\n","date":"2024-01-25T11:39:17+11:00","image":"https://mfblog.au/p/azure-open-ai-increase-performance-and-reduce-per-call-latency/cover_hu11223774430302935089.jpg","permalink":"https://mfblog.au/p/azure-open-ai-increase-performance-and-reduce-per-call-latency/","title":"Azure Open AI - Increase Performance and reduce per call latency"},{"content":"I have recently created a webpage that takes news articles from places like Azure Feeds and creates a daily summary of them using Azure Open AI, which you can read about here. But I want to make these summaries multi-modal and have them read out to me, so I can listen to them on the go. So I thought I\u0026rsquo;d use Azure AI Speech to convert the text to speech.\nTLDR What is Azure AI Speech service What is SSML How to use SSML with Azure AI Speech service Sample code What is Azure AI Speech service Azure AI Speech is a collection of speech-to-text and text-to-speech APIs that enables developers to add speech capabilities to their applications. It supports 125 languages and variants, and 60+ standard and custom voice fonts.\nWhat is SSML Speech Synthesis Markup Language (SSML) is an XML-based markup language that provides a standard way to mark up text for the generation of synthetic speech. SSML is a W3C specification that is supported by all major speech synthesis engines.\nMicrosoft has a great article here on SSML and it\u0026rsquo;s primary use cases.\nControlling pronunciation Choosing the voice Define the input text structure Controlling the pronunciation can bee really useful if you work in a domain/industry that has a lot of acronyms or jargon. For example, I work in the IT industry and Microsoft, where there are a lot of acronyms. So I can use SSML to tell Azure AI Speech how to pronounce them correctly.\nChoosing the voice is almost my favourite part. I love looking through the catalog of voices and choosing the one that I like the most. For the Azure AI Speech service, you can choose from 60+ standard and custom voice fonts. To find out what standard voices are available in your region, you can run the below command in your shell;\n1 2 3 curl --location --request GET \u0026#39;https://southeastasia.tts.speech.microsoft.com/cognitiveservices/voices/list\u0026#39; \\ --header \u0026#39;Ocp-Apim-Subscription-Key: xxxx-yyyy-zzzz\u0026#39; | jq \u0026#39;.[] | select(.Locale | contains (\u0026#34;en-NZ\u0026#34;))\u0026#39; The above command sends a GET request to https://southeastasia.tts.speech.microsoft.com/cognitiveservices/voices/list, then pipes the output to jq, which is a lightweight and flexible command-line JSON processor. The jq command filters the output to only show the voices that are available in the en-NZ locale.\nPlease replace southeastasia with the region that you have deployed your Speech service to and replace the Ocp-Apim-Subscription-Key with your key. You can find your key in the Azure portal under your Speech service resource.\nYou can also change the locale to the one that you want to use and you will get a list of voices that are available for you to use.\n And what\u0026rsquo;s even better, you can train a custom neural voice if you wish https://learn.microsoft.com/en-us/azure/ai-services/speech-service/custom-neural-voice or create a personal AI generated replication of your voice https://learn.microsoft.com/en-us/azure/ai-services/speech-service/personal-voice-overview.\nHow to use SSML with Azure AI Speech service I am new to Azure AI Speech service and SSML. The best way I have found to interact with Azure AI Speech service is to use the Speech Studio. Once in there find the Text to speech section, then select Audio Content creation.\nNext you can create a new file or folder. Click on new Text file.\nOnce in the editor you can enter your text and then select the voice that you want to use. At this point, if you don\u0026rsquo;t want to use SSML you don\u0026rsquo;t have to. You can just use the default experience and happily create an audio file from text. But if you want to use SSML, you can click on the SSML button and enter your SSML code.\nOnce you have entered your SSML code, you can click on the play button to hear what it sounds like. If you are happy with it, you can then click on the export button to download the audio file, plain text or the SSML code.\nSample code Now that I have some familiarity with Azure AI Speech service and SSML, I can now use it in my code. I have created a simple Python script that takes a string as input and converts it to an audio file using Azure AI Speech service. It then saves the audio into Azure BLOB storage as an MP3.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import azure.cognitiveservices.speech as speechsdk from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, ContentSettings # Connect to Azure BLOB storage storageaccount = \u0026#39;DefaultEndpointsProtocol=https;AccountName=aaa-bbb-ccc;AccountKey=xxx-yyy-zzz==;EndpointSuffix=core.windows.net\u0026#39; blob_service_client = BlobServiceClient.from_connection_string(storageaccount) # Creates an instance of a speech config with specified subscription key and service region. speech_key, service_region = \u0026#34;ddd-eee-fff\u0026#34;, \u0026#34;australiaeast\u0026#34; speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region) # Create ssml string ssml_string = \u0026#39;\u0026#39;\u0026#39; \u0026lt;speak xmlns=\u0026#34;http://www.w3.org/2001/10/synthesis\u0026#34; xmlns:mstts=\u0026#34;http://www.w3.org/2001/mstts\u0026#34; xmlns:emo=\u0026#34;http://www.w3.org/2009/10/emotionml\u0026#34; version=\u0026#34;1.0\u0026#34; xml:lang=\u0026#34;en-US\u0026#34;\u0026gt;\u0026lt;voice name=\u0026#34;en-US-GuyNeural\u0026#34;\u0026gt;\u0026lt;s /\u0026gt;\u0026lt;mstts:express-as style=\u0026#34;newscast\u0026#34;\u0026gt; Hello and welcome to the daily AI Generated News Summary for Thursday 8th December 2024 . I\u0026#39;m your host Guy and here are today\u0026#39;s headlines \u0026lt;/mstts:express-as\u0026gt;\u0026lt;s /\u0026gt;\u0026lt;/voice\u0026gt; \u0026lt;voice name=\u0026#34;en-US-JennyNeural\u0026#34;\u0026gt;\u0026lt;mstts:express-as style=\u0026#34;newscast\u0026#34;\u0026gt; Thanks Guy. I\u0026#39;m Jenny and today we have a new article by azurefeeds entitled hello \u0026lt;/mstts:express-as\u0026gt;\u0026lt;/voice\u0026gt;\u0026lt;/speak\u0026gt; \u0026#39;\u0026#39;\u0026#39; # Send string to Azure speech service speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None) result = speech_synthesizer.speak_ssml(ssml_string) # Get audio data audio_data = result.audio_data # Upload audio to Azure BLOB storage mp3upload = blob_service_client.get_blob_client(container=\u0026#39;20231211\u0026#39;, blob=today + \u0026#39;.mp3\u0026#39;) mp3upload.upload_blob(audio_data, overwrite=True, content_settings=ContentSettings(content_type=\u0026#39;audio/mpeg\u0026#39;))  To test out this code, you can create the SSML in the Speech Studio and then copy and paste it the SSML into the ssml_string variable.\nHow am I using this I have added this process into my Azure Function that creates the daily summary of Azure news. As you can see above, I tried to make it sound like a News desk by having a host (Guy) and a presenter (Jenny). So in my code, I have Guy do a little intro, then I have Jenny read all of the articles, then I have Guy do a little outro. You can see my full code here: https://github.com/fredderf204/ai-gen-news-summary/blob/main/html-email/init.py and I have a put a snippet below;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 blob_service_client = BlobServiceClient.from_connection_string(storageaccount) today = datetime.today().strftime(\u0026#39;%Y%m%d\u0026#39;) dow = datetime.now().strftime(\u0026#39;%A\u0026#39;) dateword = datetime.now().strftime(\u0026#39;%B %d, %Y\u0026#39;) container_client = blob_service_client.get_container_client(today) ssml_string = \u0026#34;\u0026lt;speak xmlns=\\\u0026#34;http://www.w3.org/2001/10/synthesis\\\u0026#34; xmlns:mstts=\\\u0026#34;http://www.w3.org/2001/mstts\\\u0026#34; xmlns:emo=\\\u0026#34;http://www.w3.org/2009/10/emotionml\\\u0026#34; version=\\\u0026#34;1.0\\\u0026#34; xml:lang=\\\u0026#34;en-US\\\u0026#34;\u0026gt;\u0026lt;voice name=\\\u0026#34;en-US-GuyNeural\\\u0026#34;\u0026gt;\u0026lt;s /\u0026gt;\u0026lt;mstts:express-as style=\\\u0026#34;newscast\\\u0026#34;\u0026gt;Hello and welcome to the daily AI Generated News Summary for \u0026#34; + dow + \u0026#34; \u0026#34; + dateword + \u0026#34;. I\u0026#39;m your host Guy\u0026lt;/mstts:express-as\u0026gt;\u0026lt;s /\u0026gt;\u0026lt;/voice\u0026gt;\u0026lt;voice name=\\\u0026#34;en-US-JennyNeural\\\u0026#34;\u0026gt;\u0026lt;mstts:express-as style=\\\u0026#34;newscast\\\u0026#34;\u0026gt;And I\u0026#39;m Jenny. Here are your headlines for today.\u0026#34; bloblist = container_client.list_blobs() for blob in bloblist: logging.info(blob.name) blob_client = container_client.get_blob_client(blob.name) downloader = blob_client.download_blob(max_concurrency=1, encoding=\u0026#39;UTF-8\u0026#39;) blob_text = downloader.readall() blob_text_json = json.loads(blob_text) ssml_string += \u0026#34;The next article is entitled \u0026#34; + blob_text_json.get(\u0026#39;title\u0026#39;) + \u0026#34; and was published on \u0026#34; + blob_text_json.get(\u0026#39;author\u0026#39;) + \u0026#34;. Here is the summary \u0026#34; + blob_text_json.get(\u0026#39;summary\u0026#39;) ssml_string += \u0026#39;\u0026lt;/mstts:express-as\u0026gt;\u0026lt;s /\u0026gt;\u0026lt;/voice\u0026gt;\u0026lt;voice name=\u0026#34;en-US-GuyNeural\u0026#34;\u0026gt;\u0026lt;mstts:express-as style=\u0026#34;newscast\u0026#34;\u0026gt;Thanks Jenny. That\\\u0026#39;s all from the news desk today. Thanks for listening and have a great day.\u0026lt;/mstts:express-as\u0026gt;\u0026lt;/voice\u0026gt;\u0026lt;/speak\u0026gt;\u0026#39; speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region) speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None) result = speech_synthesizer.speak_ssml(ssml_string) audio_data = result.audio_data mp3upload = blob_service_client.get_blob_client(container=today, blob=today + \u0026#39;.mp3\u0026#39;) mp3upload.upload_blob(audio_data, overwrite=True, content_settings=ContentSettings(content_type=\u0026#39;audio/mpeg\u0026#39;)) Conclusion I hope this article gives you to confidence and some ideas on how you can use SSML with Azure AI Speech service. I am really enjoying learning about Azure AI Speech service and SSML and I am looking forward to using it more in the future.\nI hope you found this post useful. If you have any questions, feel free to reach out to me on Twitter or Linkedin.\n","date":"2023-12-14T13:27:03+11:00","image":"https://mfblog.au/p/using-ssml-with-azure-ai-speech-service/cover_hu1895510977640052601.jpeg","permalink":"https://mfblog.au/p/using-ssml-with-azure-ai-speech-service/","title":"Using SSML with Azure AI Speech service"},{"content":"Are you trying to keep up with all of the daily Azure news? Are you finding it difficult and overwhelming? Well, I do  but I have a solution for you  I\u0026rsquo;ve created an Azure Function centred process that takes news articles from places like Azure Feeds and creates a summary of them using Azure Open AI.\nTLDR GitHub Repo Why I created this How it works How to use it What\u0026rsquo;s next GitHub Repo The code for this project can be found here. Feel free to fork it and make it your own. Or if you have any issues with the code or have any suggestions, please raise an issue \nWhy I created this I created this project for a few reasons:\nI find it very difficult to keep up with all of the Azure news. There is so much of it and it\u0026rsquo;s coming from so many different places. I wanted to create a way to summarise all of the news into one place. I wanted a baseline of what has happened in the Azure world over the last 24 hours, but I wanted a system where if I saw something that was interesting, I could go and read the full article. I wanted a use case to build something with Azure Open AI. I find this is the best way for me to learn something new. How it works I have an Azure Function that runs every 24 hours on a timer trigger called mf-az-feeds. It gets the latest news articles from Azure Feeds using RSS and sends a JSON message to an Azure storage queue. The JSON contains fields like; title, description, link, and published date. Huge shout out to Azure Feeds as it\u0026rsquo;s the place I have been getting my Azure news daily for many years! This process could be scaled to get news from other sources as diagramed, but I haven\u0026rsquo;t done that yet. The queueworker Azure Function reads each JSON message of the storage queue (queue trigger) and then uses Azure Open AI to create a summary of each article. Then the summary is combined with the JSON contains fields of title, description, link, and published date and stored in BLOB storage as JSON. I choose this process because I wanted a copy of the JSON and BLOB storage is cheap! Each day has it\u0026rsquo;s own container and each article has it\u0026rsquo;s own JSON file. The html-email function has a time trigger that run every 24 hours (and 20 minutes after the mf-az-feeds function) and gets the JSON from BLOB storage and creates a HTML file. I store a copy of the html file in the days storage container and a copy in to the static website folder ($web) in Azure Storage. Then the function sends a REST request to my Logic App with the static website folder url, which in turn gets emailed to me. I haven\u0026rsquo;t documented the static website folder ($web) copy in the above diagram, but it\u0026rsquo;s there. And so I can go the same URL each day, and it will be up to date with a AI generated summary of the Azure news for that day. For example, this is what today\u0026rsquo;s webpage looks like;\nHow to use it Prerequisites Azure subscription Azure Function App Add the below Function App Configuration Application settings once known. \u0026ldquo;targetrss\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;logicappurl\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;containerurl\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;storageaccount\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026lt;\u0026mdash;this is the connection string of your storage account. \u0026ldquo;aoaiendpoint\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;aoaikey\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;aoaimodel\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;queuename\u0026rdquo;: \u0026ldquo;rssprocess\u0026rdquo; \u0026ldquo;staticurl\u0026rdquo;: \u0026quot;\u0026quot; \u0026lt;\u0026mdash;this is the static website URL of your storage account. Azure Storage Account Blob Storage Container (remember the url path to this container. Static website hosting enabled (remember this URL) SAS Key (remember the key) Queue with name rssprocess (this is hardcoded in the queueworker function.json) Azure Open AI resource (remember the endpoint name, key and model name.) Azure Logic App (remember the URL) Deploy the Azure Function App Below are the steps to deploy the Azure Function App to your Azure subscription from your local machine. I know this is the best way to do this, but I haven\u0026rsquo;t had time to create an ARM template yet. If you want to create an ARM template, please raise a PR \nClone the repo Open the repo in VS Code Make a Python virtual environment Install the requirements.txt Create a local.settings.json file and add the below settings. (This step isn\u0026rsquo;t required if you are deploying to Azure, but if you ever want to debug it locally, it will be.) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \u0026#34;IsEncrypted\u0026#34;: false, \u0026#34;Values\u0026#34;: { \u0026#34;AzureWebJobsStorage\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;FUNCTIONS_WORKER_RUNTIME\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;targetrss\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;logicappurl\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;containerurl\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;storageaccount\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;aoaiendpoint\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;aoaikey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;aoaimodel\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;queuename\u0026#34;: \u0026#34;rssprocess\u0026#34;, \u0026#34;staticurl\u0026#34;: \u0026#34;\u0026#34; } } Deploy the Azure Function App to your Azure subscription using the Azure Functions extension in VS Code. Tip: I also like to have the function locally because I can then use the Azure extension in VS Code to run the function in Azure. In case something is wrong or borken and it needs a manual trigger.\nWhat\u0026rsquo;s next I have a few ideas on what I want to do next with this project. I\u0026rsquo;m not sure which one I will do first, but I will do them all eventually. Add a comment below if you have any suggestions or want to help out \n","date":"2023-11-24T15:46:04+11:00","image":"https://mfblog.au/p/ai-generated-azure-news-summary/cover_hu14341690920362458927.jpg","permalink":"https://mfblog.au/p/ai-generated-azure-news-summary/","title":"AI Generated Azure News Summary"},{"content":"Running Azure Functions locally isn\u0026rsquo;t something new, but it\u0026rsquo;s being a while since I\u0026rsquo;ve done it and I thought I\u0026rsquo;d share my experiences with some of the new tools, using Python and triggering local functions using time and queue triggers.\nTLDR Use Visual Studio Code Install the Azure Functions extension Install the Azure Functions Core Tools Install the Azurite Install the Azure Storage Explorer VS Code If you are developing Azure functions locally, I couldn\u0026rsquo;t recommend Visual Studio Code enough. It\u0026rsquo;s a great editor and has a lot of great extensions that make developing Azure Functions locally a breeze. Also it\u0026rsquo;s free and available on your favourite platform - Linux, macOS, and Windows.\nDeveloping Functions locally There is already a great article here on how to develop Azure Functions by using Visual Studio Code.\nThe Azure Functions extension provides these benefits:\nEdit, build, and run functions on your local development computer. Publish your Azure Functions project directly to Azure. Write your functions in various languages while taking advantage of the benefits of Visual Studio Code.  But to develop Azure Functions locally, you must install the Azure Functions Core Tools which enables an integrated local debugging experience. When using the Azure Functions extension, the easiest way to install Core Tools is by running the Azure Functions: Install or Update Azure Functions Core Tools command from the command pallet.\nPython There isn\u0026rsquo;t anything in particular you need to do make Python work with Azure Functions, but I couldn\u0026rsquo;t recommend enough creating a virtual environment and using the same Python version that Azure Functions use in Azure. This will help with any issues you may have with dependencies once you deploy your Function to Azure.\nLocal debugging I can\u0026rsquo;t believe that I wasn\u0026rsquo;t doing this from the start. The first few times I would right my Azure Function locally, deploy it to Azure and wait and see if it worked.\n This is a terrible idea and slowed down my development significantly. Once I started to debug locally, I was able to do so much more in a shorter amount of time.\nWhat the heck is Azurite? Have you ever wanted to run and debug your function locally, but your Azure Function needs to interact with Azure Storage?\nAzurite is a great tool that provides a local Azure Storage emulator that emulates the Azure Blob, Queue, and Table services for local development purposes. It is the best way to test your Azure Storage code without going to Azure.\nFor instance, one of my Azure Functions had to write to Azure Blob storage. Azurite come in super handy as it can emulate Azure Blob storage locally. But what I did notice was that Azurite would validate my request to Azure Blob storage, but would not actually create the container and Blob object. But for me, having the request validated is good enough for development.\nAlso starting the Azurite emulator is super easy. Once install via a VSCode extension, look at the bottom of VSCode and you should see some button that look like this\nYou simply click on one of those services to start them up.\nSpeaking of development, Azurite can be run as a docker container, so I can imagine how that could be automated and added to a CI/CD pipeline. This way you can test your app in a pipeline before deploying to Azure, speeding up development ans shortening the dev cycle.\nHow to trigger functions locally Next challenge I faced was how to do trigger these functions locally? One function was setup on a time trigger to run once per day, and the other had a Azure queue trigger.\nTime trigger I struggled to find the answer to this on  but buried deep in the comments in this thread I found the answer.\n You have to send a POST request to the local admin endpoint http://localhost:{port}/admin/functions/{function_name} with Content-Type = application/json and body of { \u0026quot;input\u0026quot;: null }\nAs you can see above I used Postman to send a POST request to the local admin endpoint of http://localhost:7071/admin/functions/mf-az-feeds. Also please not that { \u0026quot;input\u0026quot;: null } was the only body data that triggered the function. If I sent any other value for the input, the function would not trigger.\nQueue trigger This was slightly simpler, but requires 3 pre-reqs\nInstalling Azure Storage Explorer. Starting up the Azurite queue service in Visual Studio Code. The local.settings.json file on your Function project needs to have the following well-known account and key \u0026quot;storageaccount\u0026quot;: \u0026quot;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;DefaultEndpointsProtocol=http;BlobEndpoint=http://127.0.0.1:10000/devstoreaccount1;QueueEndpoint=http://127.0.0.1:10001/devstoreaccount1;TableEndpoint=http://127.0.0.1:10002/devstoreaccount1;\u0026quot;, Then I used the Azure Storage Explorer to connect to the local Azurite queue service and crate a new queue with the same name as my queue trigger. Next I dropped a message in that queue, which triggered the function.\nConclusion I hope this helps you with your local Azure Function development. I know it helped me and I\u0026rsquo;m sure I\u0026rsquo;ll be using these tools again in the future.\nI hope you found this post useful. If you have any questions, feel free to reach out to me on Twitter or Linkedin.\n","date":"2023-11-13T16:44:06+11:00","image":"https://mfblog.au/p/running-azure-functions-locally/cover_hu7149281738775394313.jpg","permalink":"https://mfblog.au/p/running-azure-functions-locally/","title":"Running Azure Functions locally"},{"content":"I\u0026rsquo;ve been toying with the idea of making a custom event badge for a while now, and I finally got around to it!\nThe reason being is that I love connecting with people, but I hate constantly getting my phone out of my pocket to show my Linkedin QR code. So I thought it would be cool to have a badge with a QR code on it that people could scan, get my details and connect on Linkedin \nTLDR Take a screenshot of your LinkedIn QR code. Convert it to a SVG image. I used Adobe jpg-to-svg. Convert the SVG to a STL file. I used imagetostl. Make the event badge using 3d modelling software. I used Tinkercad Print STL to physical object  The last step requires a 3d printer.\nGetting your LinkedIn QR code This process wasn\u0026rsquo;t too difficult, but it was a bit of a pain. I\u0026rsquo;m sure there\u0026rsquo;s a better way to do it, but this is what I did.\nOpen the Linkedin app on your phone. Click on the search bar on the top of the screen. Click on the QR code icon in the top right corner. Screenshot the QR code. Email the screenshot to yourself. Crop the QR code out of the screenshot. like below: Converting the QR code to a SVG I used Adobe jpg-to-svg to convert the QR code to a SVG image. It\u0026rsquo;s a free online tool that does the job well. Not too much to see about this process, just upload the image and download the SVG.\nConverting the SVG to a STL I used imagetostl to convert the SVG to a STL file. It\u0026rsquo;s a free online tool that does the job well.\nThe reason we are converting this file into a STL, is so I can import it into Tinkercad to create the badge. If you are using another 3d modelling tool that can import SVG files, you can skip this step.\nGo to imagetostl Upload your SVG file Select Invert Output like below and convert Your outpt put should look like the below image. Download the STL file. Making the badge I used Tinkercad to make the badge. I find Tinkercad to be the easiest 3d modelling tool to use, but you can use whatever you like. I have tried other (Blender, Fusion 360, etc) but I find them to be too complicated for my needs.\nOpen Tinkercad and create a flat card to put your QR code on. I made mine 110mm x 50mm x 1mm. Tip: 1mm is too thin. It bends too much and I feel like it could break. Next time I will make it 2mm thick.\nI also added a hole to the top so I could attach a lanyard to it.\nNext I imported my QR Code and place it on the card. I also made it 1mm thick.\nAlso I added my first name and company to the right of the card. I used the default font and made it 1mm high.\nLastly I downloaded the STL file to my PC.\nPrinting the badge Tip: The printing process will vary depending on what 3d printer you have. I have a Bambu Lab P1P and the Bambu Lab AMS, which means I can print in multiple colours. I printed the card in white and the QR code and lettering in black.\nOpen the downloaded STL in Bambu Studio.\nAdd the desired colours to the STL.\nPrint the STL using defaults.\nand 27 minutes later, you have your event badge!\nConclusion I\u0026rsquo;m really happy with how the badge turned out. I\u0026rsquo;ve already used it at a few events and it\u0026rsquo;s been a great conversation starter. I\u0026rsquo;ve also had a few people ask me how I made it, so I thought I would write this blog post to share the process.\nI hope you found this post useful. If you have any questions, feel free to reach out to me on Twitter or Linkedin.\n","date":"2023-11-13T11:55:10+11:00","image":"https://mfblog.au/p/3d-printed-event-badge/cover_hu10872174209198077439.jpg","permalink":"https://mfblog.au/p/3d-printed-event-badge/","title":"3d printed event badge"},{"content":"After a fairly long hiatus, I\u0026rsquo;m back blogging again!\nLooking forward to pumping out some new interesting content soon!\n","date":"2023-11-13T10:35:57+11:00","image":"https://mfblog.au/p/im-back/cover_hu1159857464004467079.jpg","permalink":"https://mfblog.au/p/im-back/","title":"I'm back"}]